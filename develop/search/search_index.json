{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#runn-random-utility-neural-network","title":"RUNN: Random Utility Neural Network","text":""},{"location":"contributing/","title":"Contributing","text":"<p>runn is an actively maintained and utilised project.</p>"},{"location":"contributing/#how-to-contribute","title":"How to contribute","text":"<p>to report issues, request features, or exchange with our community, just follow the links below.</p> <p>Is something not working?</p> <p> Report a bug</p> <p>Missing information in our docs?</p> <p> Report a docs issue</p> <p>Want to submit an idea?</p> <p> Request a change</p> <p>Have a question or need help?</p> <p> Ask a question</p>"},{"location":"contributing/#developing-runn","title":"Developing runn","text":"<p>To find beginner-friendly existing bugs and feature requests you may like to start out with, take a look at our good first issues.</p>"},{"location":"contributing/#setting-up-a-development-environment","title":"Setting up a development environment","text":"<p>To create a development environment for runn, with all libraries required for development and quality assurance installed, it is easiest to install runn using the mamba package manager, as follows:</p> <ol> <li>Install mamba with the Mambaforge executable for your operating system.</li> <li>Open the command line (or the \"miniforge prompt\" in Windows).</li> <li>Download (a.k.a., clone) the runn repository: <code>git clone git@github.com:JoseAngelMartinB/runn.git</code></li> <li>Change into the <code>runn</code> directory: <code>cd runn</code></li> <li>Create the runn mamba environment: <code>mamba create -n runn -c conda-forge --file requirements/base.txt --file requirements/dev.txt</code></li> <li>Activate the runn mamba environment: <code>mamba activate runn</code></li> <li>Install the runn package into the environment, in editable mode and ignoring dependencies (we have dealt with those when creating the mamba environment): <code>pip install --no-deps -e .</code></li> </ol> <p>All together:</p> <pre><code>git clone git@github.com:JoseAngelMartinB/runn.git\ncd runn\nmamba create -n runn -c conda-forge --file requirements/base.txt --file requirements/dev.txt\nmamba activate runn\npip install --no-deps -e .\npython -m ipykernel install --user --name runn\n</code></pre> <p>If installing directly with pip, you can install these libraries using the <code>dev</code> option, i.e., <code>pip install -e '.[dev]'</code> Either way, you should add your environment as a jupyter kernel, so the example notebooks can run in the tests: <code>ipython kernel install --user --name=runn</code> If you plan to make changes to the code then please make regular use of the following tools to verify the codebase while you work:</p> <ul> <li><code>pre-commit</code>: run <code>pre-commit install</code> in your command line to load inbuilt checks that will run every time you commit your changes. The checks are: 1. check no large files have been staged, 2. lint python files for major errors, 3. format python files to conform with the PEP8 standard. You can also run these checks yourself at any time to ensure staged changes are clean by calling <code>pre-commit</code>.</li> <li><code>pytest</code> - run the unit test suite and check test coverage.</li> </ul> <p>Note</p> <p>If you already have an environment called <code>runn</code> on your system (e.g., for a stable installation of the package), you will need to chose a different environment name. You will then need to add this as a pytest argument when running the tests: <code>pytest --nbmake-kernel=[my-env-name]</code>.</p>"},{"location":"contributing/#rapid-fire-testing","title":"Rapid-fire testing","text":"<p>The following options allow you to strip down the test suite to the bare essentials: 1. The test suite includes unit tests and integration tests (in the form of jupyter notebooks found in the <code>examples</code> directory). The integration tests can be slow, so if you want to avoid them during development, you should run <code>pytest tests/</code>. 2. You can avoid generating coverage reports, by adding the <code>--no-cov</code> argument: <code>pytest --no-cov</code>. 3. By default, the tests run with up to two parallel threads, to increase this to e.g. 4 threads: <code>pytest -n4</code>.</p> <p>All together:</p> <pre><code>pytest tests/ --no-cov -n4\n</code></pre> <p>Note</p> <p>You cannot debug failing tests and have your tests run in parallel, you will need to set <code>-n0</code> if using the <code>--pdb</code> flag</p>"},{"location":"contributing/#memory-profiling","title":"Memory profiling","text":"<p>Note</p> <p>When you open a pull request (PR), one of the GitHub actions will run memory profiling for you. This means you don't have to do any profiling locally. However, if you can, it is still good practice to do so as you will catch issues earlier.</p> <p>runn can be memory intensive; we like to ensure that any development to the core code does not exacerbate this. If you are running on a UNIX device (i.e., not on Windows), you can test whether any changes you have made adversely impact memory and time performance as follows:</p> <ol> <li>Install memray in your <code>runn</code> mamba environment: <code>mamba install memray pytest-memray</code>.</li> <li>Run the memory profiling integration test: <code>pytest -p memray -m \"high_mem\" --no-cov</code>.</li> <li>Optionally, to visualise the memory allocation, run <code>pytest -p memray -m \"high_mem\" --no-cov --memray-bin-path=[my_path] --memray-bin-prefix=[my_prefix]</code> - where you must define <code>[my_path]</code> and <code>[my_prefix]</code> - followed by <code>memray flamegraph [my_path]/[my_prefix]-tests-test_100_memory_profiling.py-test_mem.bin</code>. You will then find the HTML report at <code>[my_path]/memray-flamegraph-[my_prefix]-tests-test_100_memory_profiling.py-test_mem.html</code>.</li> </ol> <p>All together:</p> <pre><code>mamba install memray pytest-memray\npytest -p memray -m \"high_mem\" --no-cov --memray-bin-path=[my_path] --memray-bin-prefix=[my_prefix]\nmemray flamegraph [my_path]/[my_prefix]-tests-test_100_memory_profiling.py-test_mem.bin\n</code></pre> <p>For more information on using memray, refer to their documentation.</p>"},{"location":"contributing/#submitting-changes","title":"Submitting changes","text":"<p>To contribute changes:</p> <ol> <li>Fork the project on GitHub.</li> <li>Create a feature branch to work on in your fork (<code>git checkout -b new-fix-or-feature</code>).</li> <li>Test your changes using <code>pytest</code>.</li> <li>Commit your changes to the feature branch (you should have <code>pre-commit</code> installed to ensure your code is correctly formatted when you commit changes).</li> <li>Push the branch to GitHub (<code>git push origin new-fix-or-feature</code>).</li> <li>On GitHub, create a new pull request from the feature branch.</li> </ol>"},{"location":"contributing/#pull-requests","title":"Pull requests","text":"<p>Before submitting a pull request, check whether you have:</p> <ul> <li>Added your changes to <code>CHANGELOG.md</code>.</li> <li>Added or updated documentation for your changes.</li> <li>Added tests if you implemented new functionality.</li> </ul> <p>When opening a pull request, please provide a clear summary of your changes!</p>"},{"location":"contributing/#commit-messages","title":"Commit messages","text":"<p>Please try to write clear commit messages. One-line messages are fine for small changes, but bigger changes should look like this:</p> <pre><code>A brief summary of the commit (max 50 characters)\n\nA paragraph or bullet-point list describing what changed and its impact,\ncovering as many lines as needed.\n</code></pre>"},{"location":"contributing/#code-conventions","title":"Code conventions","text":"<p>Start reading our code and you'll get the hang of it.</p> <p>We mostly follow the official Style Guide for Python Code (PEP8).</p> <p>We have chosen to use the uncompromising code formatter <code>black</code> and the linter <code>ruff</code>. When run from the root directory of this repo, <code>pyproject.toml</code> should ensure that formatting and linting fixes are in line with our custom preferences (e.g., 100 character maximum line length). The philosophy behind using <code>black</code> is to have uniform style throughout the project dictated by code. Since <code>black</code> is designed to minimise diffs, and make patches more human readable, this also makes code reviews more efficient. To make this a smooth experience, you should run <code>pre-commit install</code> after setting up your development environment, so that <code>black</code> makes all the necessary fixes to your code each time you commit, and so that <code>ruff</code> will highlight any errors in your code. If you prefer, you can also set up your IDE to run these two tools whenever you save your files, and to have <code>ruff</code> highlight erroneous code directly as you type. Take a look at their documentation for more information on configuring this.</p> <p>We require all new contributions to have docstrings for all modules, classes and methods. When adding docstrings, we request you use the Google docstring style.</p>"},{"location":"contributing/#release-checklist","title":"Release checklist","text":""},{"location":"contributing/#pre-release","title":"Pre-release","text":"<ul> <li> Make sure all unit and integration tests pass (This is best done by creating a pre-release pull request).</li> <li> Re-run tutorial Jupyter notebooks (<code>pytest examples/ --overwrite</code>).</li> <li> Make sure documentation builds without errors (<code>mike deploy [version]</code>, where <code>[version]</code> is the current minor release of the form <code>X.Y</code>).</li> <li> Make sure the changelog is up-to-date, especially that new features and backward incompatible changes are clearly marked.</li> </ul>"},{"location":"contributing/#create-release","title":"Create release","text":"<ul> <li> Bump the version number in <code>runn/__init__.py</code></li> <li> Update the changelog with final version number of the form <code>vX.Y.Z</code>, release date, and github <code>compare</code> link (at the bottom of the page).</li> <li> Commit with message <code>Release vX.Y.Z</code>, then add a <code>vX.Y.Z</code> tag.</li> <li> Create a release pull request to verify that the conda package builds successfully.</li> <li> Once the PR is approved and merged, create a release through the GitHub web interface, using the same tag, titling it <code>Release vX.Y.Z</code> and include all the changelog elements that are not flagged as internal.</li> </ul>"},{"location":"contributing/#post-release","title":"Post-release","text":"<ul> <li> Update the changelog, adding a new <code>[Unreleased]</code> heading.</li> <li> Update <code>runn/__init__.py</code> to the next version appended with <code>.dev0</code>, in preparation for the next main commit.</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#setting-up-a-user-environment","title":"Setting up a user environment","text":"<p>As a <code>runn</code> user, it is easiest to install using the mamba package manager, as follows:</p> <ol> <li>Install mamba with the Mambaforge executable for your operating system.</li> <li> <p>Open the command line (or the \"miniforge prompt\" in Windows).</p> </li> <li> <p>Create the runn mamba environment: <code>mamba create -n runn -c conda-forge -c JoseAngelMartinB runn</code></p> </li> <li>Activate the runn mamba environment: <code>mamba activate runn</code></li> </ol> <p>All together:</p> <pre><code>mamba create -n runn -c conda-forge -c JoseAngelMartinB runn\n</code></pre>"},{"location":"installation/#running-the-example-notebooks","title":"Running the example notebooks","text":"<p>If you have followed the non-developer installation instructions above, you will need to install <code>jupyter</code> into your <code>runn</code> environment to run the example notebooks:</p> <pre><code>mamba install -n runn jupyter\n</code></pre> <p>With Jupyter installed, it's easiest to then add the environment as a jupyter kernel:</p> <pre><code>mamba activate runn\nipython kernel install --user --name=runn\njupyter notebook\n</code></pre>"},{"location":"installation/#choosing-a-different-environment-name","title":"Choosing a different environment name","text":"<p>If you would like to use a different name to <code>runn</code> for your mamba environment, the installation becomes (where <code>[my-env-name]</code> is your preferred name for the environment):</p> <pre><code>mamba create -n [my-env-name] -c conda-forge --file requirements/base.txt\nmamba activate [my-env-name]\nipython kernel install --user --name=[my-env-name]\n</code></pre>"},{"location":"installation/#setting-up-a-development-environment","title":"Setting up a development environment","text":"<p>The install instructions are slightly different to create a development environment compared to a user environment:</p> <pre><code>git clone git@github.com:JoseAngelMartinB/runn.git\ncd runn\nmamba create -n runn -c conda-forge --file requirements/base.txt --file requirements/dev.txt\nmamba activate runn\npip install --no-deps -e .\npython -m ipykernel install --user --name runn\n</code></pre> <p>For more detailed installation instructions specific to developing the runn codebase, see our development documentation.</p>"},{"location":"examples/1_intro_to_runn/","title":"Introduction to RUNN: Random Utility Neural Network","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport runn\n\nrunn.display_info()\n</pre> %load_ext autoreload %autoreload 2  import runn  runn.display_info()  <pre>2023-11-28 16:00:31.930578: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n</pre> <pre>\n---------------------------------- RUNN info -----------------------------------\nRUNN: Random Utility Neural Network\nVersion: 0.1.0\nAuthor: Jos\u00e9 \u00c1ngel Mart\u00edn Baos\n\nSystem information:\nTensorFlow version: 2.14.0\nNumber of CPUs available: 1\nNumber of GPUs available: 0\n--------------------------------------------------------------------------------\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/1_intro_to_runn/#introduction-to-runn-random-utility-neural-network","title":"Introduction to RUNN: Random Utility Neural Network\u00b6","text":""},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"CHANGELOG/#unreleased","title":"Unreleased","text":""},{"location":"CHANGELOG/#fixed","title":"Fixed","text":""},{"location":"CHANGELOG/#added","title":"Added","text":""},{"location":"CHANGELOG/#changed","title":"Changed","text":""},{"location":"CHANGELOG/#removed","title":"Removed","text":""},{"location":"CHANGELOG/#v010-2023-11-08","title":"[v0.1.0] - 2023-11-08","text":"<p>Initial release.</p>"},{"location":"reference/runn/econometric_indicators/","title":"runn.econometric_indicators","text":"<p>Useful econometric indicators that can be extracted from the models.</p>"},{"location":"reference/runn/econometric_indicators/#runn.econometric_indicators.market_shares","title":"<code>market_shares(model, x)</code>","text":"<p>Calculate the market shares for each alternative.</p> PARAMETER  DESCRIPTION <code>model</code> <p>The model to be used. It should be a model defined in the runn.models module.</p> <p> TYPE: <code>BaseModel</code> </p> <code>x</code> <p>The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.</p> <p> TYPE: <code>Union[Tensor, ndarray, DataFrame]</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>Numpy array with the market shares for each alternative.</p> Source code in <code>runn/econometric_indicators.py</code> <pre><code>def market_shares(model: BaseModel, x: Union[tf.Tensor, np.ndarray, pd.DataFrame]) -&gt; np.ndarray:\n    \"\"\"Calculate the market shares for each alternative.\n\n    Args:\n        model: The model to be used. It should be a model defined in the runn.models module.\n        x: The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.\n\n    Returns:\n        Numpy array with the market shares for each alternative.\n    \"\"\"\n    if isinstance(x, pd.DataFrame):\n        x = x.values\n    if isinstance(x, np.ndarray):\n        x = tf.convert_to_tensor(x)\n\n    # Compute the matrix of probabilities\n    pred_probabilities = model.predict(x)\n\n    # Compute the market shares\n    market_shares = np.round(np.mean(pred_probabilities, axis=0) * 100, 4)\n\n    return market_shares\n</code></pre>"},{"location":"reference/runn/econometric_indicators/#runn.econometric_indicators.value_of_time","title":"<code>value_of_time(model, x, time_attribute, cost_attribute, alt, scaler=None)</code>","text":"<p>Calculate the value of time (VOT) for a given alternative. The VOT is calculated for all the observations in the input data.</p> PARAMETER  DESCRIPTION <code>model</code> <p>The model to be used. It should be a model defined in the runn.models module.</p> <p> TYPE: <code>BaseModel</code> </p> <code>x</code> <p>The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.</p> <p> TYPE: <code>Union[Tensor, ndarray, DataFrame]</code> </p> <code>time_attribute</code> <p>The index or name of the time attribute.</p> <p> TYPE: <code>Union[int, str]</code> </p> <code>cost_attribute</code> <p>The index or name of the cost attribute.</p> <p> TYPE: <code>Union[int, str]</code> </p> <code>alt</code> <p>The index of the alternative to be analysed.</p> <p> TYPE: <code>int</code> </p> <code>scaler</code> <p>If the data was scaled before training the model, the scaler object should be provided. Currently, only the StandardScaler and MinMaxScaler from sklearn.preprocessing are supported. Default: None.</p> <p> TYPE: <code>Optional[object]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>Numpy array with the VOT for each observation in the input data.</p> Source code in <code>runn/econometric_indicators.py</code> <pre><code>def value_of_time(\n    model: BaseModel,\n    x: Union[tf.Tensor, np.ndarray, pd.DataFrame],\n    time_attribute: Union[int, str],\n    cost_attribute: Union[int, str],\n    alt: int,\n    scaler: Optional[object] = None,\n) -&gt; np.ndarray:\n    \"\"\"Calculate the value of time (VOT) for a given alternative. The VOT is calculated for all\n    the observations in the input data.\n\n    Args:\n        model: The model to be used. It should be a model defined in the runn.models module.\n        x: The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.\n        time_attribute: The index or name of the time attribute.\n        cost_attribute: The index or name of the cost attribute.\n        alt: The index of the alternative to be analysed.\n        scaler: If the data was scaled before training the model, the scaler object should be provided. Currently,\n            only the StandardScaler and MinMaxScaler from sklearn.preprocessing are supported. Default: None.\n\n    Returns:\n        Numpy array with the VOT for each observation in the input data.\n    \"\"\"\n    return -willingness_to_pay(model, x, time_attribute, cost_attribute, alt, scaler)\n</code></pre>"},{"location":"reference/runn/econometric_indicators/#runn.econometric_indicators.willingness_to_pay","title":"<code>willingness_to_pay(model, x, analysed_attribute, cost_attribute, alt, scaler=None)</code>","text":"<p>Calculate the willingness to pay (WTP) for a given attribute and alternative. The WTP is calculated for all the observations in the input data.</p> PARAMETER  DESCRIPTION <code>model</code> <p>The model to be used. It should be a model defined in the runn.models module.</p> <p> TYPE: <code>BaseModel</code> </p> <code>x</code> <p>The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.</p> <p> TYPE: <code>Union[Tensor, ndarray, DataFrame]</code> </p> <code>analysed_attribute</code> <p>The index or name of the attribute to be analysed.</p> <p> TYPE: <code>Union[int, str]</code> </p> <code>cost_attribute</code> <p>The index or name of the cost attribute.</p> <p> TYPE: <code>Union[int, str]</code> </p> <code>alt</code> <p>The index of the alternative to be analysed.</p> <p> TYPE: <code>int</code> </p> <code>scaler</code> <p>If the data was scaled before training the model, the scaler object should be provided. Currently, only the StandardScaler and MinMaxScaler from sklearn.preprocessing are supported. Default: None.</p> <p> TYPE: <code>Optional[object]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>Numpy array with the WTP for each observation in the input data.</p> Source code in <code>runn/econometric_indicators.py</code> <pre><code>def willingness_to_pay(\n    model: BaseModel,\n    x: Union[tf.Tensor, np.ndarray, pd.DataFrame],\n    analysed_attribute: Union[int, str],\n    cost_attribute: Union[int, str],\n    alt: int,\n    scaler: Optional[object] = None,\n) -&gt; np.ndarray:\n    \"\"\"Calculate the willingness to pay (WTP) for a given attribute and alternative. The WTP is calculated for all\n    the observations in the input data.\n\n    Args:\n        model: The model to be used. It should be a model defined in the runn.models module.\n        x: The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.\n        analysed_attribute: The index or name of the attribute to be analysed.\n        cost_attribute: The index or name of the cost attribute.\n        alt: The index of the alternative to be analysed.\n        scaler: If the data was scaled before training the model, the scaler object should be provided. Currently,\n            only the StandardScaler and MinMaxScaler from sklearn.preprocessing are supported. Default: None.\n\n    Returns:\n        Numpy array with the WTP for each observation in the input data.\n    \"\"\"\n    if scaler is not None and not isinstance(scaler, (StandardScaler, MinMaxScaler)):\n        raise ValueError(\n            \"The scaler object should be either a StandardScaler or a MinMaxScaler from \" \"sklearn.preprocessing.\"\n        )\n\n    if isinstance(analysed_attribute, str) and isinstance(x, pd.DataFrame):\n        if analysed_attribute not in model.attributes:\n            raise ValueError(\"The analysed attribute is not present in the model.\")\n        analysed_attribute = x.columns.get_loc(analysed_attribute)\n    elif not isinstance(analysed_attribute, int):\n        raise ValueError(\n            \"The analysed attribute should be either an integer indicating the index of the attribute \"\n            \"or a string with the name of the attribute.\"\n        )\n\n    if isinstance(cost_attribute, str) and isinstance(x, pd.DataFrame):\n        if cost_attribute not in model.attributes:\n            raise ValueError(\"The cost attribute is not present in the model.\")\n        cost_attribute = x.columns.get_loc(cost_attribute)\n    elif not isinstance(cost_attribute, int):\n        raise ValueError(\n            \"The cost attribute should be either an integer indicating the index of the attribute \"\n            \"or a string with the name of the attribute.\"\n        )\n\n    if analysed_attribute == cost_attribute:\n        raise ValueError(\"The analysed attribute cannot be the same as the cost attribute.\")\n    if analysed_attribute &gt;= len(model.attributes):\n        raise ValueError(\"The analysed attribute index is out of range.\")\n    if cost_attribute &gt;= len(model.attributes):\n        raise ValueError(\"The cost attribute index is out of range.\")\n\n    if isinstance(x, pd.DataFrame):\n        x = x.values\n    if isinstance(x, np.ndarray):\n        x = tf.convert_to_tensor(x)\n\n    if alt &gt;= model.n_alt:\n        raise ValueError(\"The alternative index is out of range.\")\n    if alt &lt; 0:\n        raise ValueError(\"The alternative index cannot be negative.\")\n\n    # Check if the model supports obtaining the utility function\n    compute_gradient_using_utility = True\n    try:\n        model.get_utility(tf.zeros((1, x.shape[1])))\n    except NotSupportedError:\n        compute_gradient_using_utility = False\n\n    if compute_gradient_using_utility:\n        # Compute the gradient of the utility function with respect to the analysed attributes using the tensorflow\n        with tf.GradientTape() as tape:\n            tape.watch(x)\n            pred_utility = model.get_utility(x)\n            pred_utility = pred_utility[:, alt]\n        grad = tape.gradient(pred_utility, x)\n    else:\n        # Compute the gradient of the probabilities with respect to the analysed attributes using the tensorflow\n        with tf.GradientTape() as tape:\n            tape.watch(x)\n            pred_probabilities = model(x)\n            pred_probabilities = pred_probabilities[:, alt]\n        grad = tape.gradient(pred_probabilities, x)\n\n    grad_cost = grad[:, cost_attribute]\n    grad_analysed_attr = grad[:, analysed_attribute]\n\n    # Undo the scaling effect on the WTP\n    if scaler is not None:\n        if type(scaler) is StandardScaler:\n            if isinstance(analysed_attribute, str):\n                analysed_attr_scale = scaler.scale_[list(scaler.feature_names_in_).index(analysed_attribute)]\n            else:\n                analysed_attr_scale = scaler.scale_[\n                    list(scaler.feature_names_in_).index(model.attributes[analysed_attribute])\n                ]\n            if isinstance(cost_attribute, str):\n                cost_attr_scale = scaler.scale_[list(scaler.feature_names_in_).index(cost_attribute)]\n            else:\n                cost_attr_scale = scaler.scale_[list(scaler.feature_names_in_).index(model.attributes[cost_attribute])]\n            grad_analysed_attr = grad_analysed_attr / analysed_attr_scale\n            grad_cost = grad_cost / cost_attr_scale\n        elif type(scaler) is MinMaxScaler:\n            raise NotImplementedError(\"MinMaxScaler not implemented yet.\")  # TODO: Implement\n\n    # Compute the WTP\n    wtp = -grad_analysed_attr / grad_cost\n    wtp = wtp.numpy()\n\n    return wtp\n</code></pre>"},{"location":"reference/runn/keras/layers/gather/","title":"runn.keras.layers.gather","text":""},{"location":"reference/runn/keras/layers/gather/#runn.keras.layers.gather.Gather","title":"<code>Gather(indices, axis=1, **kwargs)</code>","text":"<p>             Bases: <code>Layer</code></p> <p>Custom layer to gather the elements of a tensor based on an index tensor.</p> PARAMETER  DESCRIPTION <code>indices</code> <p>A tensor with the indices of the elements to gather.</p> <p> TYPE: <code>Tensor</code> </p> <code>axis</code> <p>The axis along which to gather the elements. Default: 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> Source code in <code>runn/keras/layers/gather.py</code> <pre><code>def __init__(self, indices: tf.Tensor, axis: int = 1, **kwargs):\n    super(Gather, self).__init__(**kwargs)\n    self.indices = indices\n    self.axis = axis\n</code></pre>"},{"location":"reference/runn/keras/layers/gather/#runn.keras.layers.gather.Gather.axis","title":"<code>axis = axis</code>  <code>instance-attribute</code>","text":""},{"location":"reference/runn/keras/layers/gather/#runn.keras.layers.gather.Gather.indices","title":"<code>indices = indices</code>  <code>instance-attribute</code>","text":""},{"location":"reference/runn/keras/layers/gather/#runn.keras.layers.gather.Gather.call","title":"<code>call(inputs)</code>","text":"Source code in <code>runn/keras/layers/gather.py</code> <pre><code>def call(self, inputs: tf.Tensor) -&gt; tf.Tensor:\n    # Perform the gather operation\n    return tf.gather(inputs, indices=self.indices, axis=self.axis)\n</code></pre>"},{"location":"reference/runn/keras/layers/gather/#runn.keras.layers.gather.Gather.get_config","title":"<code>get_config()</code>","text":"Source code in <code>runn/keras/layers/gather.py</code> <pre><code>def get_config(self) -&gt; dict:\n    config = super(Gather, self).get_config()\n    config.update({\"indices\": self.indices, \"axis\": self.axis})\n    return config\n</code></pre>"},{"location":"reference/runn/metrics/","title":"runn.metrics","text":"<p>Useful metrics for evaluating the performance of the neural network models.</p>"},{"location":"reference/runn/metrics/#runn.metrics.AMPCA","title":"<code>AMPCA(proba, y)</code>","text":"<p>Arithmetic Mean Probability of Correct Assignment (AMPCA) metric.</p> PARAMETER  DESCRIPTION <code>proba</code> <p>Matrix of predicted choice probabilities. Each row corresponds to a sample and each column to an</p> <p> TYPE: <code>ndarray</code> </p> <code>y</code> <p>Array of true choices. Each element corresponds to the index of the chosen alternative.</p> <p> TYPE: <code>ndarray</code> </p> RETURNS DESCRIPTION <code>float</code> <p>AMPCA metric.</p> Source code in <code>runn/metrics.py</code> <pre><code>def AMPCA(proba: np.ndarray, y: np.ndarray) -&gt; float:\n    \"\"\"Arithmetic Mean Probability of Correct Assignment (AMPCA) metric.\n\n    Args:\n        proba: Matrix of predicted choice probabilities. Each row corresponds to a sample and each column to an\n        alternative.\n        y: Array of true choices. Each element corresponds to the index of the chosen alternative.\n\n    Returns:\n        AMPCA metric.\n    \"\"\"\n    sum = 0\n    i = 0\n    for sel_mode in y:\n        sum = sum + proba[i, sel_mode]\n        i += 1\n    N = i - 1\n    return sum / N\n</code></pre>"},{"location":"reference/runn/metrics/#runn.metrics.CEL","title":"<code>CEL(proba, y)</code>","text":"<p>Cross-Entropy Loss (CEL) metric.</p> PARAMETER  DESCRIPTION <code>proba</code> <p>Matrix of predicted choice probabilities. Each row corresponds to a sample and each column to an</p> <p> TYPE: <code>ndarray</code> </p> <code>y</code> <p>Array of true choices. Each element corresponds to the index of the chosen alternative.</p> <p> TYPE: <code>ndarray</code> </p> RETURNS DESCRIPTION <code>float</code> <p>CEL metric.</p> Source code in <code>runn/metrics.py</code> <pre><code>def CEL(proba: np.ndarray, y: np.ndarray) -&gt; float:\n    \"\"\"Cross-Entropy Loss (CEL) metric.\n\n    Args:\n        proba: Matrix of predicted choice probabilities. Each row corresponds to a sample and each column to an\n        alternative.\n        y: Array of true choices. Each element corresponds to the index of the chosen alternative.\n\n    Returns:\n        CEL metric.\n    \"\"\"\n    sum = 0\n    i = 0\n    for sel_mode in y:\n        sum = sum + np.log(proba[i, sel_mode])\n        i += 1\n    N = i - 1\n    return -sum / N\n</code></pre>"},{"location":"reference/runn/metrics/#runn.metrics.GMPCA","title":"<code>GMPCA(proba, y)</code>","text":"<p>Geometric Mean Probability of Correct Assignment (GMPCA) metric.</p> PARAMETER  DESCRIPTION <code>proba</code> <p>Matrix of predicted choice probabilities. Each row corresponds to a sample and each column to an</p> <p> TYPE: <code>ndarray</code> </p> <code>y</code> <p>Array of true choices. Each element corresponds to the index of the chosen alternative.</p> <p> TYPE: <code>ndarray</code> </p> RETURNS DESCRIPTION <code>float</code> <p>GMPCA metric.</p> Source code in <code>runn/metrics.py</code> <pre><code>def GMPCA(proba: np.ndarray, y: np.ndarray) -&gt; float:\n    \"\"\"Geometric Mean Probability of Correct Assignment (GMPCA) metric.\n\n    Args:\n        proba: Matrix of predicted choice probabilities. Each row corresponds to a sample and each column to an\n        alternative.\n        y: Array of true choices. Each element corresponds to the index of the chosen alternative.\n\n    Returns:\n        GMPCA metric.\n    \"\"\"\n    return np.exp(-CEL(proba, y))\n</code></pre>"},{"location":"reference/runn/metrics/#runn.metrics.accuracy","title":"<code>accuracy(proba, y)</code>","text":"<p>Accuracy metric.</p> PARAMETER  DESCRIPTION <code>proba</code> <p>Matrix of predicted choice probabilities. Each row corresponds to a sample and each column to an</p> <p> TYPE: <code>ndarray</code> </p> <code>y</code> <p>Array of true choices. Each element corresponds to the index of the chosen alternative.</p> <p> TYPE: <code>ndarray</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Accuracy metric.</p> Source code in <code>runn/metrics.py</code> <pre><code>def accuracy(proba: np.ndarray, y: np.ndarray) -&gt; float:\n    \"\"\"Accuracy metric.\n\n    Args:\n        proba: Matrix of predicted choice probabilities. Each row corresponds to a sample and each column to an\n        alternative.\n        y: Array of true choices. Each element corresponds to the index of the chosen alternative.\n\n    Returns:\n        Accuracy metric.\n    \"\"\"\n    return np.mean(np.argmax(proba, axis=1) == y)\n</code></pre>"},{"location":"reference/runn/models/altspec_mono_nn/","title":"runn.models.altspec_mono_nn","text":""},{"location":"reference/runn/models/altspec_mono_nn/#runn.models.altspec_mono_nn.warning_manager","title":"<code>warning_manager = WarningManager()</code>  <code>module-attribute</code>","text":""},{"location":"reference/runn/models/altspec_mono_nn/#runn.models.altspec_mono_nn.AltSpecMonoNN","title":"<code>AltSpecMonoNN(params=None)</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Alternative-specific monotonic neural network model for choice modeling.</p> PARAMETER  DESCRIPTION <code>params</code> <p>Dictionary with the model parameters.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> Source code in <code>runn/models/altspec_mono_nn.py</code> <pre><code>def __init__(self, params: dict = None) -&gt; None:\n    \"\"\"Alternative-specific monotonic neural network model for choice modeling.\n\n    Args:\n        params: Dictionary with the model parameters.\n    \"\"\"\n\n    super().__init__(params)\n</code></pre>"},{"location":"reference/runn/models/altspec_nn/","title":"runn.models.altspec_nn","text":""},{"location":"reference/runn/models/altspec_nn/#runn.models.altspec_nn.warning_manager","title":"<code>warning_manager = WarningManager()</code>  <code>module-attribute</code>","text":""},{"location":"reference/runn/models/altspec_nn/#runn.models.altspec_nn.AltSpecNN","title":"<code>AltSpecNN(attributes=None, n_alt=None, alt_spec_attrs=None, shared_attrs=None, socioec_attrs=None, layers_dim=[25, 25], activation='relu', regularizer=None, regularization_rate=0.001, dropout=0.0, batch_norm=False, learning_rate=0.001, optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], filename=None, warnings=True)</code>","text":"<p>             Bases: <code>DNN</code></p> <p>Alternative-specific neural network model for choice modeling.</p> PARAMETER  DESCRIPTION <code>attributes</code> <p>List with the attributes names in the model, in the same order as in the input data. If None, the model cannot be initialized unless it is loaded from a file. Default: None.</p> <p> TYPE: <code>Optional[list]</code> DEFAULT: <code>None</code> </p> <code>n_alt</code> <p>Number of alternatives in the choice set. If None, the model cannot be initialized unless it is loaded from a file. Default: None.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>alt_spec_attrs</code> <p>Dictionary with the alternative-specific attributes. The keys are the index of the alternative and the values are lists with the names of the alternative-specific attributes. The alternative-specific attributes must be a subset of the attributes defined in the model. If None, the model cannot be initialized unless it is loaded from a file. Default: None.</p> <p> TYPE: <code>Optional[Dict[int, list]]</code> DEFAULT: <code>None</code> </p> <code>shared_attrs</code> <p>List with the names of the attributes that are shared across all alternatives. The shared attributes must be a subset of the attributes defined in the model. If None, the model cannot be initialized unless it is loaded from a file. Default: None.</p> <p> TYPE: <code>Optional[list]</code> DEFAULT: <code>None</code> </p> <code>socioec_attrs</code> <p>List with the names of the socio-economic attributes of each decision maker. The socio-economic attributes must be a subset of the attributes defined in the model.  If None, the model cannot be initialized unless it is loaded from a file. Default: None.</p> <p> TYPE: <code>Optional[list]</code> DEFAULT: <code>None</code> </p> <code>layers_dim</code> <p>List with the number of neurons in each hidden layer, the length of the list is the number of hidden layers. Default: [25, 25].</p> <p> TYPE: <code>list</code> DEFAULT: <code>[25, 25]</code> </p> <code>activation</code> <p>Activation function to use in the hidden layers. Can be either a string or a list of strings. See https://keras.io/api/layers/activations/ for the available activations. Default: 'relu'.</p> <p> TYPE: <code>Union[str, list]</code> DEFAULT: <code>'relu'</code> </p> <code>regularizer</code> <p>Type of regularization to apply. Possible values: 'l1', 'l2' or 'l1_l2'. Default: None.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>regularization_rate</code> <p>Regularization rate if regularizer is not None. Default: 0.001.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.001</code> </p> <code>learning_rate</code> <p>Learning rate of the optimizer. Default: 0.001.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.001</code> </p> <code>dropout</code> <p>Dropout rate to use in the hidden layers. Can be either a float or a list of floats. If a float is provided, the same dropout rate will be used in all the hidden layers. Default: 0.0.</p> <p> TYPE: <code>Union[float, list]</code> DEFAULT: <code>0.0</code> </p> <code>batch_norm</code> <p>Whether to use batch normalization or not. Default: False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>optimizer</code> <p>Optimizer to use. Can be either a string or a tf.keras.optimizers.Optimizer. Default: 'adam'.</p> <p> TYPE: <code>Union[str, Optimizer]</code> DEFAULT: <code>'adam'</code> </p> <code>loss</code> <p>Loss function to use. Can be either a string or a tf.keras.losses.Loss. Default: 'categorical_crossentropy'.</p> <p> TYPE: <code>Union[str, Loss]</code> DEFAULT: <code>'categorical_crossentropy'</code> </p> <code>metrics</code> <p>List of metrics to be evaluated by the model during training and testing. Each of this can be either a string or a tf.keras.metrics.Metric. Default: ['accuracy'].</p> <p> TYPE: <code>list</code> DEFAULT: <code>['accuracy']</code> </p> <code>filename</code> <p>Load a previously trained model from a file. If None, a new model will be initialized. When loading a model from a file, the previous parameters will be ignored. Default: None.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>warnings</code> <p>Whether to show warnings or not. Default: True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>runn/models/altspec_nn.py</code> <pre><code>def __init__(\n    self,\n    attributes: Optional[list] = None,\n    n_alt: Optional[int] = None,\n    alt_spec_attrs: Optional[Dict[int, list]] = None,\n    shared_attrs: Optional[list] = None,\n    socioec_attrs: Optional[list] = None,\n    layers_dim: list = [25, 25],\n    activation: Union[str, list] = \"relu\",\n    regularizer: Optional[str] = None,\n    regularization_rate: float = 0.001,\n    dropout: Union[float, list] = 0.0,\n    batch_norm: bool = False,\n    learning_rate: float = 0.001,\n    optimizer: Union[str, tf.keras.optimizers.Optimizer] = \"adam\",\n    loss: Union[str, tf.keras.losses.Loss] = \"categorical_crossentropy\",\n    metrics: list = [\"accuracy\"],\n    filename: Optional[str] = None,\n    warnings: bool = True,\n) -&gt; None:\n    # Initialize the parameters of the base class\n    super(DNN, self).__init__(\n        attributes=attributes,\n        n_alt=n_alt,\n        layers_dim=layers_dim,\n        regularizer=regularizer,\n        regularization_rate=regularization_rate,\n        learning_rate=learning_rate,\n        optimizer=optimizer,\n        loss=loss,\n        metrics=metrics,\n        filename=filename,\n        warnings=warnings,\n    )\n    if filename is None:\n        self._initialize_dnn_params(activation=activation, dropout=dropout, batch_norm=batch_norm)\n        self._initialize_AltSpecNN_params(\n            alt_spec_attrs=alt_spec_attrs, shared_attrs=shared_attrs, socioec_attrs=socioec_attrs\n        )\n        self._build()\n    self._compile()\n</code></pre>"},{"location":"reference/runn/models/altspec_nn/#runn.models.altspec_nn.AltSpecNN.get_utility","title":"<code>get_utility(x)</code>","text":"<p>Get the utility of each alternative for a given set of observations.</p> PARAMETER  DESCRIPTION <code>x</code> <p>The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.</p> <p> TYPE: <code>Union[Tensor, ndarray, DataFrame]</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>Numpy array with the utility of each alternative for each observation in the input data.</p> Source code in <code>runn/models/altspec_nn.py</code> <pre><code>def get_utility(self, x: Union[tf.Tensor, np.ndarray, pd.DataFrame]) -&gt; np.ndarray:\n    \"\"\"Get the utility of each alternative for a given set of observations.\n\n    Args:\n        x: The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.\n\n    Returns:\n        Numpy array with the utility of each alternative for each observation in the input data.\n    \"\"\"\n    if self.fitted is False:\n        raise Exception(\"The model is not fitted yet. Please call fit() first.\")\n\n    if isinstance(x, pd.DataFrame):\n        x = x.values\n    if isinstance(x, np.ndarray):\n        x = tf.convert_to_tensor(x)\n\n    utility_model = Model(inputs=self.keras_model.input, outputs=self.keras_model.get_layer(\"U\").output)\n    return utility_model(x)\n</code></pre>"},{"location":"reference/runn/models/altspec_nn/#runn.models.altspec_nn.AltSpecNN.load","title":"<code>load(path)</code>","text":"<p>Load the model from a file.</p> PARAMETER  DESCRIPTION <code>path</code> <p>Path to the file where the model is saved.</p> <p> TYPE: <code>str</code> </p> Source code in <code>runn/models/altspec_nn.py</code> <pre><code>def load(self, path: str) -&gt; None:\n    \"\"\"Load the model from a file.\n\n    Args:\n        path: Path to the file where the model is saved.\n    \"\"\"\n    if not isinstance(path, str):\n        raise ValueError(\"The 'path' parameter should be a string.\")\n    # Check that the str ends with .zip\n    if not path.endswith(\".zip\"):\n        raise ValueError(\"The 'path' parameter should be a .zip file.\")\n    else:\n        # Remove the .zip extension\n        aux_files = path[:-4]\n        # Get the last index of the '/' character\n        idx = aux_files.rfind(\"/\")\n        # Get the name of the file without the path\n        aux_name = aux_files[idx + 1 :]\n\n    try:\n        # Extract the files inside an temporal auxiliary folder\n        os.mkdir(aux_files)\n        with ZipFile(path, \"r\") as zip:\n            zip.extractall(path=aux_files)\n\n        # Load model info\n        with open(aux_files + \"/\" + aux_name + \"_info.json\", \"r\") as f:\n            model_info = json.load(f)\n        if model_info[\"model\"] != \"AltSpecNN\":\n            msg = (\n                \"The model in the file is not a 'AltSpecNN' model. The model cannot be loaded.\",\n                \"Please try using the '{}' model instead.\".format(model_info[\"model\"]),\n            )\n            raise ValueError(msg)\n\n        # Check runn version\n        major, minor, patch = model_info[\"runn_version\"].split(\".\")\n        if (\n            int(major) &gt; int(runn.__version__.split(\".\")[0])\n            or (\n                int(major) == int(runn.__version__.split(\".\")[0])\n                and int(minor) &gt; int(runn.__version__.split(\".\")[1])\n            )\n            or (\n                int(major) == int(runn.__version__.split(\".\")[0])\n                and int(minor) == int(runn.__version__.split(\".\")[1])\n                and int(patch) &gt; int(runn.__version__.split(\".\")[2])\n            )\n        ):\n            msg = (\n                \"The model was created with a newer version of runn ({}). \"\n                \"Please update runn to version {} or higher.\".format(model_info[\"runn_version\"], runn.__version__)\n            )\n            raise IncompatibleVersionError(msg)\n\n        # Load the parameters of the model\n        (\n            self.attributes,\n            self.n_alt,\n            self.alt_spec_attrs,\n            self.shared_attrs,\n            self.socioec_attrs,\n            self.layers_dim,\n            self.activation,\n            self.regularizer,\n            self.regularization_rate,\n            self.dropout,\n            self.batch_norm,\n            self.learning_rate,\n            self.optimizer,\n            self.loss,\n            self.metrics,\n        ) = pickle.load(open(aux_files + \"/\" + aux_name + \"_params.pkl\", \"rb\"))\n        self._initialize_AltSpecNN_params(\n            alt_spec_attrs=self.alt_spec_attrs, shared_attrs=self.shared_attrs, socioec_attrs=self.socioec_attrs\n        )\n\n        # Load the keras model\n        self._build()\n        self.keras_model.load_weights(aux_files + \"/\" + aux_name + \"_model.h5\")\n\n        # Load the history\n        self.history = pickle.load(open(aux_files + \"/\" + aux_name + \"_history.pkl\", \"rb\"))\n        self.fitted = model_info[\"fitted\"]\n    except Exception as e:\n        raise e\n    finally:\n        # Delete the auxiliary folder\n        for file in os.listdir(aux_files):\n            os.remove(aux_files + \"/\" + file)\n        os.rmdir(aux_files)\n</code></pre>"},{"location":"reference/runn/models/altspec_nn/#runn.models.altspec_nn.AltSpecNN.save","title":"<code>save(path='model.zip')</code>","text":"<p>Save the model to a file.</p> PARAMETER  DESCRIPTION <code>path</code> <p>Path to the file where the model will be saved. Default: 'model.zip'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'model.zip'</code> </p> Source code in <code>runn/models/altspec_nn.py</code> <pre><code>def save(self, path: str = \"model.zip\") -&gt; None:\n    \"\"\"Save the model to a file.\n\n    Args:\n        path: Path to the file where the model will be saved. Default: 'model.zip'.\n    \"\"\"\n    if not isinstance(path, str):\n        raise ValueError(\"The 'path' parameter should be a string.\")\n    if path[-4:] != \".zip\":\n        path += \".zip\"\n    aux_files = path[:-4]\n\n    files = []\n    # Save model info as json\n    model_info = {\n        \"model\": \"AltSpecNN\",\n        \"runn_version\": runn.__version__,\n        \"creation_date\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"fitted\": self.fitted,\n    }\n    with open(aux_files + \"_info.json\", \"w\") as f:\n        json.dump(model_info, f)\n    files.append(aux_files + \"_info.json\")\n\n    # Save the parameters of the model\n    # Save all the parameters of the model in a pickle file except the keras model\n    pickle.dump(\n        [\n            self.attributes,\n            self.n_alt,\n            self.alt_spec_attrs,\n            self.shared_attrs,\n            self.socioec_attrs,\n            self.layers_dim,\n            self.activation,\n            self.regularizer,\n            self.regularization_rate,\n            self.dropout,\n            self.batch_norm,\n            self.learning_rate,\n            self.optimizer,\n            self.loss,\n            self.metrics,\n        ],\n        open(aux_files + \"_params.pkl\", \"wb\"),\n    )\n    files.append(aux_files + \"_params.pkl\")\n\n    # Save the keras model\n    self.keras_model.save_weights(aux_files + \"_model.h5\")\n    files.append(aux_files + \"_model.h5\")\n\n    # Save the history\n    pickle.dump(self.history, open(aux_files + \"_history.pkl\", \"wb\"))\n    files.append(aux_files + \"_history.pkl\")\n\n    # Compress all the files\n    with ZipFile(path, \"w\") as zip:\n        for file in files:\n            zip.write(file, os.path.basename(file))\n\n    # Delete the auxiliary files\n    for file in files:\n        os.remove(file)\n</code></pre>"},{"location":"reference/runn/models/base/","title":"runn.models.base","text":""},{"location":"reference/runn/models/base/#runn.models.base.optimizers","title":"<code>optimizers = {'adadelta': Adadelta, 'adafactor': Adafactor, 'adagrad': Adagrad, 'adam': Adam, 'adamw': AdamW, 'adamax': Adamax, 'ftrl': Ftrl, 'lion': Lion, 'nadam': Nadam, 'rmsprop': RMSprop, 'sgd': SGD}</code>  <code>module-attribute</code>","text":""},{"location":"reference/runn/models/base/#runn.models.base.warning_manager","title":"<code>warning_manager = WarningManager()</code>  <code>module-attribute</code>","text":""},{"location":"reference/runn/models/base/#runn.models.base.BaseModel","title":"<code>BaseModel(attributes=None, n_alt=None, layers_dim=[25, 25], regularizer=None, regularization_rate=0.001, learning_rate=0.001, optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], filename=None, warnings=True)</code>","text":"<p>Abstract base class for all choice models.</p> PARAMETER  DESCRIPTION <code>attributes</code> <p>List with the attributes names in the model, in the same order as in the input data. If None, the model cannot be initialized unless it is loaded from a file. Default: None.</p> <p> TYPE: <code>Optional[list]</code> DEFAULT: <code>None</code> </p> <code>n_alt</code> <p>Number of alternatives in the choice set. If None, the model cannot be initialized unless it is loaded from a file. Default: None.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>layers_dim</code> <p>List with the number of neurons in each hidden layer, the length of the list is the number of hidden layers. Default: [25, 25].</p> <p> TYPE: <code>list</code> DEFAULT: <code>[25, 25]</code> </p> <code>regularizer</code> <p>Type of regularization to apply. Possible values: 'l1', 'l2' or 'l1_l2'. Default: None.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>regularization_rate</code> <p>Regularization rate if regularizer is not None. Default: 0.001.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.001</code> </p> <code>learning_rate</code> <p>Learning rate of the optimizer. Default: 0.001.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.001</code> </p> <code>optimizer</code> <p>Optimizer to use. Can be either a string or a tf.keras.optimizers.Optimizer. Default: 'adam'.</p> <p> TYPE: <code>Union[str, Optimizer]</code> DEFAULT: <code>'adam'</code> </p> <code>loss</code> <p>Loss function to use. Can be either a string or a tf.keras.losses.Loss. Default: 'categorical_crossentropy'.</p> <p> TYPE: <code>Union[str, Loss]</code> DEFAULT: <code>'categorical_crossentropy'</code> </p> <code>metrics</code> <p>List of metrics to be evaluated by the model during training and testing. Each of this can be either a string or a tf.keras.metrics.Metric. Default: ['accuracy'].</p> <p> TYPE: <code>list</code> DEFAULT: <code>['accuracy']</code> </p> <code>filename</code> <p>Load a previously trained model from a file. If None, a new model will be initialized. When loading a model from a file, the previous parameters will be ignored. Default: None.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>warnings</code> <p>Whether to show warnings or not. Default: True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>runn/models/base.py</code> <pre><code>def __init__(\n    self,\n    attributes: Optional[list] = None,\n    n_alt: Optional[int] = None,\n    layers_dim: list = [25, 25],\n    regularizer: Optional[str] = None,\n    regularization_rate: float = 0.001,\n    learning_rate: float = 0.001,\n    optimizer: Union[str, tf.keras.optimizers.Optimizer] = \"adam\",\n    loss: Union[str, tf.keras.losses.Loss] = \"categorical_crossentropy\",\n    metrics: list = [\"accuracy\"],\n    filename: Optional[str] = None,\n    warnings: bool = True,\n) -&gt; None:\n    self._initialize_base_variables(warnings=warnings)\n    if filename is None:\n        # Initialize new model\n        self._initialize_base_params(\n            attributes=attributes,\n            n_alt=n_alt,\n            layers_dim=layers_dim,\n            regularizer=regularizer,\n            regularization_rate=regularization_rate,\n            learning_rate=learning_rate,\n            optimizer=optimizer,\n            loss=loss,\n            metrics=metrics,\n        )\n    elif isinstance(filename, str):\n        # Load model from file\n        self.load(filename)\n    else:\n        raise ValueError(\"The 'filename' parameter should be a string.\")\n</code></pre>"},{"location":"reference/runn/models/base/#runn.models.base.BaseModel.evaluate","title":"<code>evaluate(x, y, **kwargs)</code>","text":"<p>Returns the loss value &amp; metrics values for the model for a given input.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Input data. Can be a tf.Tensor, np.ndarray or pd.DataFrame.</p> <p> TYPE: <code>Union[Tensor, ndarray, DataFrame]</code> </p> <code>y</code> <p>The alternative selected by each decision maker in the sample x. Can be either a tf.Tensor or np.ndarray. It should be a 1D array with integers in the range [0, n_alt-1] or a 2D array with one-hot encoded alternatives.</p> <p> TYPE: <code>Union[Tensor, ndarray]</code> </p> <code>**kwargs</code> <p>Additional arguments passed to the keras model. See tf.keras.Model.evaluate() for details.</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Union[float, list]</code> <p>Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has</p> <code>Union[float, list]</code> <p>multiple outputs and/or metrics). See tf.keras.Model.evaluate() for details.</p> Source code in <code>runn/models/base.py</code> <pre><code>def evaluate(\n    self, x: Union[tf.Tensor, np.ndarray, pd.DataFrame], y: Union[tf.Tensor, np.ndarray], **kwargs\n) -&gt; Union[float, list]:\n    \"\"\"Returns the loss value &amp; metrics values for the model for a given input.\n\n    Args:\n        x: Input data. Can be a tf.Tensor, np.ndarray or pd.DataFrame.\n        y: The alternative selected by each decision maker in the sample x. Can be either a tf.Tensor or np.ndarray.\n            It should be a 1D array with integers in the range [0, n_alt-1] or a 2D array with one-hot encoded\n            alternatives.\n        **kwargs: Additional arguments passed to the keras model. See tf.keras.Model.evaluate() for details.\n\n    Returns:\n        Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has\n        multiple outputs and/or metrics). See tf.keras.Model.evaluate() for details.\n    \"\"\"\n    if self.fitted is False:\n        raise Exception(\"The model is not fitted yet. Please call fit() first.\")\n    if isinstance(x, pd.DataFrame):\n        x = x.values\n    if isinstance(x, np.ndarray):\n        x = tf.convert_to_tensor(x)\n    # Check if y is one-hot encoded or a 1D array with integers in the range [0, n_alt-1]\n    if isinstance(y, tf.Tensor):\n        y = y.numpy()\n    if not (len(y.shape) == 2 and y.shape[1] == self.n_alt):\n        # y is not one-hot encoded, hence it should be a 1D array with integers in the range [0, n_alt-1]\n        if np.any(y &lt; 0) or np.any(y &gt;= self.n_alt):\n            raise ValueError(\"The input parameter 'y' should contain integers in the range [0, n_alt-1].\")\n    return self.keras_model.evaluate(x, y, **kwargs)\n</code></pre>"},{"location":"reference/runn/models/base/#runn.models.base.BaseModel.fit","title":"<code>fit(x, y, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, **kwargs)</code>","text":"<p>Train the model.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Input data. Can be a tf.Tensor, np.ndarray or pd.DataFrame.</p> <p> TYPE: <code>Union[Tensor, ndarray, DataFrame]</code> </p> <code>y</code> <p>The alternative selected by each decision maker in the sample x. Can be either a tf.Tensor or np.ndarray. It should be a 1D array with integers in the range [0, n_alt-1] or a 2D array with one-hot encoded alternatives.</p> <p> TYPE: <code>Union[Tensor, ndarray]</code> </p> <code>batch_size</code> <p>Number of samples per gradient update. If unspecified, batch_size will default to 32.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>epochs</code> <p>Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided. Default: 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>verbose</code> <p>Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. Default: 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>callbacks</code> <p>List of tf.keras.callbacks.Callback instances. List of callbacks to apply during training. See tf.keras.callbacks for details. Default: None.</p> <p> TYPE: <code>Optional[list]</code> DEFAULT: <code>None</code> </p> <code>validation_split</code> <p>Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling. Default: 0.0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>validation_data</code> <p>Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. This could be a tuple (x_val, y_val) or a tuple (x_val, y_val, val_sample_weights). Default: None.</p> <p> TYPE: <code>Optional[tuple]</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Additional arguments passed to the keras model. See tf.keras.Model.fit() for details.</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>runn/models/base.py</code> <pre><code>def fit(\n    self,\n    x: Union[tf.Tensor, np.ndarray, pd.DataFrame],\n    y: Union[tf.Tensor, np.ndarray],\n    batch_size: Optional[int] = None,\n    epochs: int = 1,\n    verbose: int = 1,\n    callbacks: Optional[list] = None,\n    validation_split: float = 0.0,\n    validation_data: Optional[tuple] = None,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Train the model.\n\n    Args:\n        x: Input data. Can be a tf.Tensor, np.ndarray or pd.DataFrame.\n        y: The alternative selected by each decision maker in the sample x. Can be either a tf.Tensor or np.ndarray.\n            It should be a 1D array with integers in the range [0, n_alt-1] or a 2D array with one-hot encoded\n            alternatives.\n        batch_size: Number of samples per gradient update. If unspecified, batch_size will default to 32.\n        epochs: Number of epochs to train the model. An epoch is an iteration over the entire x and y data\n            provided. Default: 1.\n        verbose: Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. Default: 1.\n        callbacks: List of tf.keras.callbacks.Callback instances. List of callbacks to apply during training.\n            See tf.keras.callbacks for details. Default: None.\n        validation_split: Float between 0 and 1. Fraction of the training data to be used as validation data.\n            The model will set apart this fraction of the training data, will not train on it, and will evaluate\n            the loss and any model metrics on this data at the end of each epoch. The validation data is selected\n            from the last samples in the x and y data provided, before shuffling. Default: 0.0.\n        validation_data: Data on which to evaluate the loss and any model metrics at the end of each epoch. The\n            model will not be trained on this data. This could be a tuple (x_val, y_val) or a tuple (x_val, y_val,\n            val_sample_weights). Default: None.\n        **kwargs: Additional arguments passed to the keras model. See tf.keras.Model.fit() for details.\n    \"\"\"\n    # Check if the model is initialized\n    if self.keras_model is None:\n        raise ValueError(\"The model is not initialized yet. Please initialize the model first.\")\n    # Check if y is one-hot encoded or a 1D array with integers in the range [0, n_alt-1]\n    if isinstance(y, tf.Tensor):\n        y = y.numpy()\n    if not (len(y.shape) == 2 and y.shape[1] == self.n_alt):\n        # y is not one-hot encoded, hence it should be a 1D array with integers in the range [0, n_alt-1]\n        if np.any(y &lt; 0) or np.any(y &gt;= self.n_alt):\n            raise ValueError(\"The input parameter 'y' should contain integers in the range [0, n_alt-1].\")\n\n    history = self.keras_model.fit(\n        x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, **kwargs\n    )\n    self.history = history.history\n    self.fitted = True\n</code></pre>"},{"location":"reference/runn/models/base/#runn.models.base.BaseModel.get_history","title":"<code>get_history()</code>","text":"<p>Return the history of the model training.</p> RETURNS DESCRIPTION <code>dict</code> <p>A dictionary containing the loss and metrics values at the end of each epoch.</p> Source code in <code>runn/models/base.py</code> <pre><code>def get_history(self) -&gt; dict:\n    \"\"\"Return the history of the model training.\n\n    Returns:\n        A dictionary containing the loss and metrics values at the end of each epoch.\n    \"\"\"\n    if self.history is None:\n        raise Exception(\"The model is not fitted yet. Please call fit() first.\")\n    return self.history\n</code></pre>"},{"location":"reference/runn/models/base/#runn.models.base.BaseModel.get_utility","title":"<code>get_utility(x)</code>  <code>abstractmethod</code>","text":"Source code in <code>runn/models/base.py</code> <pre><code>@abstractmethod\ndef get_utility(self, x: Union[tf.Tensor, np.ndarray, pd.DataFrame]) -&gt; np.ndarray:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/runn/models/base/#runn.models.base.BaseModel.load","title":"<code>load(path)</code>  <code>abstractmethod</code>","text":"Source code in <code>runn/models/base.py</code> <pre><code>@abstractmethod\ndef load(self, path: str) -&gt; None:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/runn/models/base/#runn.models.base.BaseModel.plot_model","title":"<code>plot_model(filename=None, expand_nested=True, dpi=96)</code>","text":"<p>Generate a graphical representation of the model.</p> PARAMETER  DESCRIPTION <code>filename</code> <p>File to which the plot will be saved. If None, the plot will only be displayed on screen. Default: None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>expand_nested</code> <p>Whether to expand nested models into clusters. Default: True.</p> <p> DEFAULT: <code>True</code> </p> <code>dpi</code> <p>Resolution of the plot. Default: 96.</p> <p> TYPE: <code>int</code> DEFAULT: <code>96</code> </p> Source code in <code>runn/models/base.py</code> <pre><code>def plot_model(self, filename: str = None, expand_nested=True, dpi: int = 96) -&gt; None:\n    \"\"\"Generate a graphical representation of the model.\n\n    Args:\n        filename: File to which the plot will be saved. If None, the plot will only be displayed on screen. Default:\n            None.\n        expand_nested: Whether to expand nested models into clusters. Default: True.\n        dpi: Resolution of the plot. Default: 96.\n    \"\"\"\n    if self.keras_model is None:\n        raise ValueError(\"Keras model is not initialized yet. Please initialize the model first.\")\n    if filename is None:\n        filename = self.__class__.__name__ + \".png\"\n    return plot_model(\n        self.keras_model,\n        show_shapes=True,\n        show_layer_names=True,\n        expand_nested=expand_nested,\n        rankdir=\"TB\",\n        style=0,\n        color=True,\n        to_file=filename,\n        dpi=dpi,\n    )\n</code></pre>"},{"location":"reference/runn/models/base/#runn.models.base.BaseModel.predict","title":"<code>predict(x, **kwargs)</code>","text":"<p>Predict the choice probabilities for a given input.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Input data.</p> <p> TYPE: <code>Union[Tensor, ndarray, DataFrame]</code> </p> <code>**kwargs</code> <p>Additional arguments passed to the keras model. See tf.keras.Model.predict() for details.</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>Numpy array with the choice probabilities for each alternative.</p> Source code in <code>runn/models/base.py</code> <pre><code>def predict(self, x: Union[tf.Tensor, np.ndarray, pd.DataFrame], **kwargs) -&gt; np.ndarray:\n    \"\"\"Predict the choice probabilities for a given input.\n\n    Args:\n        x: Input data.\n        **kwargs: Additional arguments passed to the keras model. See tf.keras.Model.predict() for details.\n\n    Returns:\n        Numpy array with the choice probabilities for each alternative.\n    \"\"\"\n    if self.fitted is False:\n        raise Exception(\"The model is not fitted yet. Please call fit() first.\")\n    if isinstance(x, pd.DataFrame):\n        x = x.values\n    if isinstance(x, np.ndarray):\n        x = tf.convert_to_tensor(x)\n    return self.keras_model.predict(x, **kwargs)\n</code></pre>"},{"location":"reference/runn/models/base/#runn.models.base.BaseModel.save","title":"<code>save(path='model.zip')</code>  <code>abstractmethod</code>","text":"Source code in <code>runn/models/base.py</code> <pre><code>@abstractmethod\ndef save(self, path: str = \"model.zip\") -&gt; None:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/runn/models/base/#runn.models.base.BaseModel.summary","title":"<code>summary(line_length=100, **kwargs)</code>","text":"<p>Print a summary of the keras model.</p> PARAMETER  DESCRIPTION <code>line_length</code> <p>Total length of printed lines. Default: 100.</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>**kwargs</code> <p>Additional arguments passed to the keras model. See tf.keras.Model.summary() for details.</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>runn/models/base.py</code> <pre><code>def summary(self, line_length: int = 100, **kwargs) -&gt; None:\n    \"\"\"Print a summary of the keras model.\n\n    Args:\n        line_length: Total length of printed lines. Default: 100.\n        **kwargs: Additional arguments passed to the keras model. See tf.keras.Model.summary() for details.\n    \"\"\"\n    if self.keras_model is None:\n        raise Exception(\"Keras model is not initialized yet. Please initialize the model first.\")\n    print(\"------ {} ------\".format(self.__class__.__name__))\n    self._print_data_summary(line_length=line_length)\n    print(\"\\nSummary of the keras model:\")\n    self.keras_model.summary(line_length=line_length, **kwargs)\n</code></pre>"},{"location":"reference/runn/models/dnn/","title":"runn.models.dnn","text":""},{"location":"reference/runn/models/dnn/#runn.models.dnn.warning_manager","title":"<code>warning_manager = WarningManager()</code>  <code>module-attribute</code>","text":""},{"location":"reference/runn/models/dnn/#runn.models.dnn.DNN","title":"<code>DNN(attributes=None, n_alt=None, layers_dim=[25, 25], activation='relu', regularizer=None, regularization_rate=0.001, dropout=0.0, batch_norm=False, learning_rate=0.001, optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], filename=None, warnings=True)</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Deep neural network model for choice modeling.</p> PARAMETER  DESCRIPTION <code>attributes</code> <p>List with the attributes names in the model, in the same order as in the input data. If None, the model cannot be initialized unless it is loaded from a file. Default: None.</p> <p> TYPE: <code>Optional[list]</code> DEFAULT: <code>None</code> </p> <code>n_alt</code> <p>Number of alternatives in the choice set. If None, the model cannot be initialized unless it is loaded from a file. Default: None.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>layers_dim</code> <p>List with the number of neurons in each hidden layer, the length of the list is the number of hidden layers. Default: [25, 25].</p> <p> TYPE: <code>list</code> DEFAULT: <code>[25, 25]</code> </p> <code>activation</code> <p>Activation function to use in the hidden layers. Can be either a string or a list of strings. See https://keras.io/api/layers/activations/ for the available activations. Default: 'relu'.</p> <p> TYPE: <code>Union[str, list]</code> DEFAULT: <code>'relu'</code> </p> <code>regularizer</code> <p>Type of regularization to apply. Possible values: 'l1', 'l2' or 'l1_l2'. Default: None.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>regularization_rate</code> <p>Regularization rate if regularizer is not None. Default: 0.001.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.001</code> </p> <code>learning_rate</code> <p>Learning rate of the optimizer. Default: 0.001.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.001</code> </p> <code>dropout</code> <p>Dropout rate to use in the hidden layers. Can be either a float or a list of floats. If a float is provided, the same dropout rate will be used in all the hidden layers. Default: 0.0.</p> <p> TYPE: <code>Union[float, list]</code> DEFAULT: <code>0.0</code> </p> <code>batch_norm</code> <p>Whether to use batch normalization or not. Default: False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>optimizer</code> <p>Optimizer to use. Can be either a string or a tf.keras.optimizers.Optimizer. Default: 'adam'.</p> <p> TYPE: <code>Union[str, Optimizer]</code> DEFAULT: <code>'adam'</code> </p> <code>loss</code> <p>Loss function to use. Can be either a string or a tf.keras.losses.Loss. Default: 'categorical_crossentropy'.</p> <p> TYPE: <code>Union[str, Loss]</code> DEFAULT: <code>'categorical_crossentropy'</code> </p> <code>metrics</code> <p>List of metrics to be evaluated by the model during training and testing. Each of this can be either a string or a tf.keras.metrics.Metric. Default: ['accuracy'].</p> <p> TYPE: <code>list</code> DEFAULT: <code>['accuracy']</code> </p> <code>filename</code> <p>Load a previously trained model from a file. If None, a new model will be initialized. When loading a model from a file, the previous parameters will be ignored. Default: None.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>warnings</code> <p>Whether to show warnings or not. Default: True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>runn/models/dnn.py</code> <pre><code>def __init__(\n    self,\n    attributes: Optional[list] = None,\n    n_alt: Optional[int] = None,\n    layers_dim: list = [25, 25],\n    activation: Union[str, list] = \"relu\",\n    regularizer: Optional[str] = None,\n    regularization_rate: float = 0.001,\n    dropout: Union[float, list] = 0.0,\n    batch_norm: bool = False,\n    learning_rate: float = 0.001,\n    optimizer: Union[str, tf.keras.optimizers.Optimizer] = \"adam\",\n    loss: Union[str, tf.keras.losses.Loss] = \"categorical_crossentropy\",\n    metrics: list = [\"accuracy\"],\n    filename: Optional[str] = None,\n    warnings: bool = True,\n) -&gt; None:\n    super().__init__(\n        attributes=attributes,\n        n_alt=n_alt,\n        layers_dim=layers_dim,\n        regularizer=regularizer,\n        regularization_rate=regularization_rate,\n        learning_rate=learning_rate,\n        optimizer=optimizer,\n        loss=loss,\n        metrics=metrics,\n        filename=filename,\n        warnings=warnings,\n    )\n    if filename is None:\n        self._initialize_dnn_params(activation=activation, dropout=dropout, batch_norm=batch_norm)\n        self._build()\n    self._compile()\n</code></pre>"},{"location":"reference/runn/models/dnn/#runn.models.dnn.DNN.get_utility","title":"<code>get_utility(x)</code>","text":"<p>Get the utility of each alternative for a given set of observations.</p> PARAMETER  DESCRIPTION <code>x</code> <p>The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.</p> <p> TYPE: <code>Union[Tensor, ndarray, DataFrame]</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>Numpy array with the utility of each alternative for each observation in the input data.</p> Source code in <code>runn/models/dnn.py</code> <pre><code>def get_utility(self, x: Union[tf.Tensor, np.ndarray, pd.DataFrame]) -&gt; np.ndarray:\n    \"\"\"Get the utility of each alternative for a given set of observations.\n\n    Args:\n        x: The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.\n\n    Returns:\n        Numpy array with the utility of each alternative for each observation in the input data.\n    \"\"\"\n    if self.fitted is False:\n        raise Exception(\"The model is not fitted yet. Please call fit() first.\")\n\n    if isinstance(x, pd.DataFrame):\n        x = x.values\n    if isinstance(x, np.ndarray):\n        x = tf.convert_to_tensor(x)\n\n    utility_model = Model(inputs=self.keras_model.input, outputs=self.keras_model.get_layer(\"U\").output)\n    return utility_model(x)\n</code></pre>"},{"location":"reference/runn/models/dnn/#runn.models.dnn.DNN.load","title":"<code>load(path)</code>","text":"<p>Load the model from a file.</p> PARAMETER  DESCRIPTION <code>path</code> <p>Path to the file where the model is saved.</p> <p> TYPE: <code>str</code> </p> Source code in <code>runn/models/dnn.py</code> <pre><code>def load(self, path: str) -&gt; None:\n    \"\"\"Load the model from a file.\n\n    Args:\n        path: Path to the file where the model is saved.\n    \"\"\"\n    if not isinstance(path, str):\n        raise ValueError(\"The 'path' parameter should be a string.\")\n    # Check that the str ends with .zip\n    if not path.endswith(\".zip\"):\n        raise ValueError(\"The 'path' parameter should be a .zip file.\")\n    else:\n        # Remove the .zip extension\n        aux_files = path[:-4]\n        # Get the last index of the '/' character\n        idx = aux_files.rfind(\"/\")\n        # Get the name of the file without the path\n        aux_name = aux_files[idx + 1 :]\n\n    try:\n        # Extract the files inside an temporal auxiliary folder\n        os.mkdir(aux_files)\n        with ZipFile(path, \"r\") as zip:\n            zip.extractall(path=aux_files)\n\n        # Load model info\n        with open(aux_files + \"/\" + aux_name + \"_info.json\", \"r\") as f:\n            model_info = json.load(f)\n        if model_info[\"model\"] != \"DNN\":\n            msg = (\n                \"The model in the file is not a DNN model. The model cannot be loaded.\",\n                \"Please try using the '{}' model instead.\".format(model_info[\"model\"]),\n            )\n            raise ValueError(msg)\n\n        # Check runn version\n        major, minor, patch = model_info[\"runn_version\"].split(\".\")\n        if (\n            int(major) &gt; int(runn.__version__.split(\".\")[0])\n            or (\n                int(major) == int(runn.__version__.split(\".\")[0])\n                and int(minor) &gt; int(runn.__version__.split(\".\")[1])\n            )\n            or (\n                int(major) == int(runn.__version__.split(\".\")[0])\n                and int(minor) == int(runn.__version__.split(\".\")[1])\n                and int(patch) &gt; int(runn.__version__.split(\".\")[2])\n            )\n        ):\n            msg = (\n                \"The model was created with a newer version of runn ({}). \"\n                \"Please update runn to version {} or higher.\".format(model_info[\"runn_version\"], runn.__version__)\n            )\n            raise IncompatibleVersionError(msg)\n\n        # Load the parameters of the model\n        (\n            self.attributes,\n            self.n_alt,\n            self.layers_dim,\n            self.activation,\n            self.regularizer,\n            self.regularization_rate,\n            self.dropout,\n            self.batch_norm,\n            self.learning_rate,\n            self.optimizer,\n            self.loss,\n            self.metrics,\n        ) = pickle.load(open(aux_files + \"/\" + aux_name + \"_params.pkl\", \"rb\"))\n\n        # Load the keras model\n        self._build()\n        self.keras_model.load_weights(aux_files + \"/\" + aux_name + \"_model.h5\")\n\n        # Load the history\n        self.history = pickle.load(open(aux_files + \"/\" + aux_name + \"_history.pkl\", \"rb\"))\n        self.fitted = model_info[\"fitted\"]\n    except Exception as e:\n        raise e\n    finally:\n        # Delete the auxiliary folder\n        for file in os.listdir(aux_files):\n            os.remove(aux_files + \"/\" + file)\n        os.rmdir(aux_files)\n</code></pre>"},{"location":"reference/runn/models/dnn/#runn.models.dnn.DNN.save","title":"<code>save(path='model.zip')</code>","text":"<p>Save the model to a file.</p> PARAMETER  DESCRIPTION <code>path</code> <p>Path to the file where the model will be saved. Default: 'model.zip'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'model.zip'</code> </p> Source code in <code>runn/models/dnn.py</code> <pre><code>def save(self, path: str = \"model.zip\") -&gt; None:\n    \"\"\"Save the model to a file.\n\n    Args:\n        path: Path to the file where the model will be saved. Default: 'model.zip'.\n    \"\"\"\n    if not isinstance(path, str):\n        raise ValueError(\"The 'path' parameter should be a string.\")\n    if path[-4:] != \".zip\":\n        path += \".zip\"\n    aux_files = path[:-4]\n\n    files = []\n    # Save model info as json\n    model_info = {\n        \"model\": \"DNN\",\n        \"runn_version\": runn.__version__,\n        \"creation_date\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"fitted\": self.fitted,\n    }\n    with open(aux_files + \"_info.json\", \"w\") as f:\n        json.dump(model_info, f)\n    files.append(aux_files + \"_info.json\")\n\n    # Save the parameters of the model\n    # Save all the parameters of the model in a pickle file except the keras model\n    pickle.dump(\n        [\n            self.attributes,\n            self.n_alt,\n            self.layers_dim,\n            self.activation,\n            self.regularizer,\n            self.regularization_rate,\n            self.dropout,\n            self.batch_norm,\n            self.learning_rate,\n            self.optimizer,\n            self.loss,\n            self.metrics,\n        ],\n        open(aux_files + \"_params.pkl\", \"wb\"),\n    )\n    files.append(aux_files + \"_params.pkl\")\n\n    # Save the keras model\n    self.keras_model.save_weights(aux_files + \"_model.h5\")\n    files.append(aux_files + \"_model.h5\")\n\n    # Save the history\n    pickle.dump(self.history, open(aux_files + \"_history.pkl\", \"wb\"))\n    files.append(aux_files + \"_history.pkl\")\n\n    # Compress all the files\n    with ZipFile(path, \"w\") as zip:\n        for file in files:\n            zip.write(file, os.path.basename(file))\n\n    # Delete the auxiliary files\n    for file in files:\n        os.remove(file)\n</code></pre>"},{"location":"reference/runn/models/ensemble_dnn/","title":"runn.models.ensemble_dnn","text":""},{"location":"reference/runn/models/ensemble_dnn/#runn.models.ensemble_dnn.warning_manager","title":"<code>warning_manager = WarningManager()</code>  <code>module-attribute</code>","text":""},{"location":"reference/runn/models/ensemble_dnn/#runn.models.ensemble_dnn.EnsembleDNN","title":"<code>EnsembleDNN(attributes=None, n_alt=None, n_ensembles=5, layers_dim=[25, 25], activation='relu', regularizer=None, regularization_rate=0.001, dropout=0.0, batch_norm=False, learning_rate=0.001, optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], n_jobs=1, filename=None, warnings=True)</code>","text":"<p>             Bases: <code>DNN</code></p> <p>Ensemble of deep neural network models for choice modeling.</p> <p>attributes: List with the attributes names in the model, in the same order as in the input data. If None, the     model cannot be initialized unless it is loaded from a file. Default: None. n_alt: Number of alternatives in the choice set. If None, the model cannot be initialized unless it is loaded     from a file. Default: None. n_ensembles: Number of base DNN models in the ensemble. This value should be greater than 1. Default: 5. layers_dim: List with the number of neurons in each hidden layer, the length of the list is the number of     hidden layers. Default: [25, 25]. activation: Activation function to use in the hidden layers. Can be either a string or a list of strings.     See https://keras.io/api/layers/activations/ for the available activations. Default: 'relu'. regularizer: Type of regularization to apply. Possible values: 'l1', 'l2' or 'l1_l2'. Default: None. regularization_rate: Regularization rate if regularizer is not None. Default: 0.001. learning_rate: Learning rate of the optimizer. Default: 0.001. dropout: Dropout rate to use in the hidden layers. Can be either a float or a list of floats. If a float is     provided, the same dropout rate will be used in all the hidden layers. Default: 0.0. batch_norm: Whether to use batch normalization or not. Default: False. optimizer: Optimizer to use. Can be either a string or a tf.keras.optimizers.Optimizer. Default: 'adam'. loss: Loss function to use. Can be either a string or a tf.keras.losses.Loss. Default:     'categorical_crossentropy'. metrics: List of metrics to be evaluated by the model during training and testing. Each of this can be either     a string or a tf.keras.metrics.Metric. Default: ['accuracy']. n_jobs: Number of parallel jobs to run. If -1, all CPUs are used. If 1 is given, no parallel computing code     is used at all, which is useful for debugging. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. filename: Load a previously trained model from a file. If None, a new model will be initialized. When loading     a model from a file, the previous parameters will be ignored. Default: None. warnings: Whether to show warnings or not. Default: True.</p> Source code in <code>runn/models/ensemble_dnn.py</code> <pre><code>def __init__(\n    self,\n    attributes: Optional[list] = None,\n    n_alt: Optional[int] = None,\n    n_ensembles: int = 5,\n    layers_dim: list = [25, 25],\n    activation: Union[str, list] = \"relu\",\n    regularizer: Optional[str] = None,\n    regularization_rate: float = 0.001,\n    dropout: Union[float, list] = 0.0,\n    batch_norm: bool = False,\n    learning_rate: float = 0.001,\n    optimizer: Union[str, tf.keras.optimizers.Optimizer] = \"adam\",\n    loss: Union[str, tf.keras.losses.Loss] = \"categorical_crossentropy\",\n    metrics: list = [\"accuracy\"],\n    n_jobs: int = 1,\n    filename: Optional[str] = None,\n    warnings: bool = True,\n) -&gt; None:\n    self._initialize_base_variables(warnings=warnings)\n    if filename is None:\n        # Initialize the model parameters of a new ensemble model\n        self._initialize_base_params(\n            attributes=attributes,\n            n_alt=n_alt,\n            layers_dim=layers_dim,\n            regularizer=regularizer,\n            regularization_rate=regularization_rate,\n            learning_rate=learning_rate,\n            optimizer=optimizer,\n            loss=loss,\n            metrics=metrics,\n        )\n        self._initialize_dnn_params(activation=activation, dropout=dropout, batch_norm=batch_norm)\n        self._initialize_ensemble_params(n_ensembles=n_ensembles, n_jobs=n_jobs)\n        # Initialize the DNN models and store them in a list\n        self.ensemble_pool = []\n        for i in range(self.n_ensembles):\n            self.ensemble_pool.append(\n                DNN(\n                    attributes=self.attributes,\n                    n_alt=self.n_alt,\n                    layers_dim=self.layers_dim,\n                    activation=self.activation,\n                    regularizer=self.regularizer,\n                    regularization_rate=self.regularization_rate,\n                    dropout=self.dropout,\n                    batch_norm=self.batch_norm,\n                    learning_rate=self.learning_rate,\n                    optimizer=self.optimizer,\n                    loss=self.loss,\n                    metrics=self.metrics,\n                )\n            )\n    elif isinstance(filename, str):\n        # Load model from file\n        self.load(filename)\n        self._compile()\n    else:\n        raise ValueError(\"The 'filename' parameter should be a string.\")\n</code></pre>"},{"location":"reference/runn/models/ensemble_dnn/#runn.models.ensemble_dnn.EnsembleDNN.ensemble_pool","title":"<code>ensemble_pool = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/runn/models/ensemble_dnn/#runn.models.ensemble_dnn.EnsembleDNN.fit","title":"<code>fit(x, y, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, bagging=None, **kwargs)</code>","text":"<p>Train the ensemble model.</p> <p>Args:     x: Input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.     y: The alternative selected by each decision maker in the sample x. Can be either a tf.Tensor or np.ndarray.         It should be a 1D array with integers in the range [0, n_alt-1] or a 2D array with one-hot encoded         alternatives.     batch_size: Number of samples per gradient update. If unspecified, batch_size will default to 32.     epochs: Number of epochs to train the model. An epoch is an iteration over the entire x and y data         provided. Default: 1.     verbose: Verbosity mode. 0 = silent, 1 = ensemble progress bar, 2 = one progress bar per individual model.         3 = for each individual model, show one line per epoch. Default: 1.     callbacks: List of tf.keras.callbacks.Callback instances. List of callbacks to apply during training.         See tf.keras.callbacks for details. Default: None.     validation_split: Float between 0 and 1. Fraction of the training data to be used as validation data.         The model will set apart this fraction of the training data, will not train on it, and will evaluate         the loss and any model metrics on this data at the end of each epoch. The validation data is selected         from the last samples in the x and y data provided, before shuffling. Default: 0.0.     validation_data: Data on which to evaluate the loss and any model metrics at the end of each epoch. The         model will not be trained on this data. This could be a tuple (x_val, y_val) or a tuple (x_val, y_val,         val_sample_weights). Default: None.     bagging: Whether to use bagging or not. If None, bagging will not be used. If a float is provided, it         indicates the percentage of samples to use in each bootstrap sample. The value should be between 0.0         and 1.0. Default: None.     **kwargs: Additional arguments passed to the keras model. See tf.keras.Model.fit() for details.</p> RETURNS DESCRIPTION <code>History</code> <p>A list of tf.keras.callbacks.History objects, one for each individual DNN model. Each History object is a</p> <code>History</code> <p>record of training loss values and metrics values at successive epochs, as well as validation loss values</p> <code>History</code> <p>and validation metrics values (if applicable).</p> Source code in <code>runn/models/ensemble_dnn.py</code> <pre><code>def fit(\n    self,\n    x: Union[tf.Tensor, np.ndarray, pd.DataFrame],\n    y: Union[tf.Tensor, np.ndarray],\n    batch_size: Optional[int] = None,\n    epochs: int = 1,\n    verbose: int = 1,\n    callbacks: Optional[list] = None,\n    validation_split: float = 0.0,\n    validation_data: Optional[tuple] = None,\n    bagging: Optional[float] = None,\n    **kwargs,\n) -&gt; tf.keras.callbacks.History:\n    \"\"\"Train the ensemble model.\n\n     Args:\n        x: Input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.\n        y: The alternative selected by each decision maker in the sample x. Can be either a tf.Tensor or np.ndarray.\n            It should be a 1D array with integers in the range [0, n_alt-1] or a 2D array with one-hot encoded\n            alternatives.\n        batch_size: Number of samples per gradient update. If unspecified, batch_size will default to 32.\n        epochs: Number of epochs to train the model. An epoch is an iteration over the entire x and y data\n            provided. Default: 1.\n        verbose: Verbosity mode. 0 = silent, 1 = ensemble progress bar, 2 = one progress bar per individual model.\n            3 = for each individual model, show one line per epoch. Default: 1.\n        callbacks: List of tf.keras.callbacks.Callback instances. List of callbacks to apply during training.\n            See tf.keras.callbacks for details. Default: None.\n        validation_split: Float between 0 and 1. Fraction of the training data to be used as validation data.\n            The model will set apart this fraction of the training data, will not train on it, and will evaluate\n            the loss and any model metrics on this data at the end of each epoch. The validation data is selected\n            from the last samples in the x and y data provided, before shuffling. Default: 0.0.\n        validation_data: Data on which to evaluate the loss and any model metrics at the end of each epoch. The\n            model will not be trained on this data. This could be a tuple (x_val, y_val) or a tuple (x_val, y_val,\n            val_sample_weights). Default: None.\n        bagging: Whether to use bagging or not. If None, bagging will not be used. If a float is provided, it\n            indicates the percentage of samples to use in each bootstrap sample. The value should be between 0.0\n            and 1.0. Default: None.\n        **kwargs: Additional arguments passed to the keras model. See tf.keras.Model.fit() for details.\n\n    Returns:\n        A list of tf.keras.callbacks.History objects, one for each individual DNN model. Each History object is a\n        record of training loss values and metrics values at successive epochs, as well as validation loss values\n        and validation metrics values (if applicable).\n    \"\"\"\n    # Check if the ensemble model has been initialized\n    if self.ensemble_pool is None or len(self.ensemble_pool) == 0:\n        msg = \"The individual DNN models have not been initialized yet. Please initialize the ensemble model first.\"\n        raise ValueError(msg)\n    if isinstance(x, pd.DataFrame):\n        x = x.values\n    if isinstance(x, np.ndarray):\n        x = tf.convert_to_tensor(x)\n\n    # Check if y is one-hot encoded or a 1D array with integers in the range [0, n_alt-1]\n    if isinstance(y, tf.Tensor):\n        y = y.numpy()\n    if not (len(y.shape) == 2 and y.shape[1] == self.n_alt):\n        # y is not one-hot encoded, hence it should be a 1D array with integers in the range [0, n_alt-1]\n        if np.any(y &lt; 0) or np.any(y &gt;= self.n_alt):\n            raise ValueError(\"The input parameter 'y' should contain integers in the range [0, n_alt-1].\")\n\n    if bagging is not None:\n        # Use bagging\n        if not isinstance(bagging, float):\n            msg = \"The 'bagging' parameter should be a float.\"\n            raise ValueError(msg)\n        if bagging &lt;= 0.0 or bagging &gt; 1.0:\n            msg = \"The 'bagging' parameter should be between 0.0 and 1.0.\"\n            raise ValueError(msg)\n        # Split the data into bootstrap samples\n        bootstrap_x, bootstrap_y = [], []\n        idx = np.arange(len(x))\n        for i in range(self.n_ensembles):\n            # Select random samples with replacement from the data using the bootstrap sample size\n            bootstrap_idx = np.random.choice(idx, size=int(len(x) * bagging), replace=True)\n            bootstrap_x.append(tf.gather(x, bootstrap_idx))\n            bootstrap_y.append(y[bootstrap_idx])\n\n    if verbose == 1:\n        pb = ProgressBar(total=self.n_ensembles)\n        pb.update(0)\n    elif verbose &gt; 1:\n        print(\"Estimating the individual DNN models...\")\n\n    # Fit the ensemble model\n    for i in range(self.n_ensembles):\n        if verbose &gt; 1:\n            print(\"\\n------ DNN model {} ------\".format(i + 1))\n        if bagging is not None:\n            x_i, y_i = bootstrap_x[i], bootstrap_y[i]\n        else:\n            x_i, y_i = x, y\n        # Fit the individual DNN model\n        self.ensemble_pool[i].fit(\n            x=x_i,\n            y=y_i,\n            batch_size=batch_size,\n            epochs=epochs,\n            verbose=verbose - 1,\n            callbacks=callbacks,\n            validation_split=validation_split,\n            validation_data=validation_data,\n            **kwargs,\n        )\n\n        # Update the progress bar or print the verbose output\n        if verbose == 1:\n            pb_value_dict = {\"loss\": \"{:.4f}\".format(self.ensemble_pool[i].get_history()[\"loss\"][-1])}\n            for metric in self.metrics:\n                pb_value_dict[metric] = \"{:.4f}\".format(self.ensemble_pool[i].get_history()[metric][-1])\n            pb.update(i + 1, value_dict=pb_value_dict)\n        elif verbose &gt; 1:\n            verbose_output = \"Training - loss: {:.4f}\".format(self.ensemble_pool[i].get_history()[\"loss\"][-1])\n            for metric in self.metrics:\n                verbose_output += \" - {}: {:.4f}\".format(metric, self.ensemble_pool[i].get_history()[metric][-1])\n            print(verbose_output)\n            if validation_data is not None or validation_split &gt; 0.0:\n                verbose_output = \"Validation - loss: {:.4f}\".format(\n                    self.ensemble_pool[i].get_history()[\"val_loss\"][-1]\n                )\n                for metric in self.metrics:\n                    verbose_output += \" - {}: {:.4f}\".format(\n                        metric, self.ensemble_pool[i].get_history()[\"val_\" + metric][-1]\n                    )\n                print(verbose_output)\n\n    # Build the ensemble model\n    self._build()\n    self.fitted = True\n    # Compile the ensemble model\n    self._compile()\n\n    # Print the verbose output of the ensemble model\n    if verbose &gt;= 1:\n        # Print the final loss and metrics values\n        metrics = [\"loss\"] + self.metrics\n        print(\"\\n------ Ensemble ------\")\n        verbose_output = \"Training\"\n        ensemble_metrics = dict(zip(metrics, self.evaluate(x, y, verbose=0)))\n        for metric in ensemble_metrics:\n            verbose_output += \" - {}: {:.4f}\".format(metric, ensemble_metrics[metric])\n        print(verbose_output)\n        if validation_data is not None:\n            verbose_output = \"Validation\"\n            ensemble_metrics = dict(zip(metrics, self.evaluate(validation_data[0], validation_data[1], verbose=0)))\n            for metric in ensemble_metrics:\n                verbose_output += \" - {}: {:.4f}\".format(metric, ensemble_metrics[metric])\n            print(verbose_output)\n</code></pre>"},{"location":"reference/runn/models/ensemble_dnn/#runn.models.ensemble_dnn.EnsembleDNN.get_history","title":"<code>get_history()</code>","text":"<p>Return the history of the model training for each individual DNN model.</p> RETURNS DESCRIPTION <code>list[dict]</code> <p>List of dictionaries with the history of the training of each individual DNN model.</p> Source code in <code>runn/models/ensemble_dnn.py</code> <pre><code>def get_history(self) -&gt; list[dict]:\n    \"\"\"Return the history of the model training for each individual DNN model.\n\n    Returns:\n        List of dictionaries with the history of the training of each individual DNN model.\n    \"\"\"\n    if not self.fitted:\n        msg = \"The model has not been fitted yet. Please call the 'fit' method first.\"\n        raise ValueError(msg)\n    history = []\n    for i in range(self.n_ensembles):\n        history.append(self.ensemble_pool[i].get_history())\n    return history\n</code></pre>"},{"location":"reference/runn/models/ensemble_dnn/#runn.models.ensemble_dnn.EnsembleDNN.get_utility","title":"<code>get_utility(x)</code>","text":"<p>Get the utility of each alternative for a given set of observations.</p> PARAMETER  DESCRIPTION <code>x</code> <p>The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.</p> <p> TYPE: <code>Union[Tensor, ndarray, DataFrame]</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>Numpy array with the utility of each alternative for each observation in the input data.</p> Source code in <code>runn/models/ensemble_dnn.py</code> <pre><code>def get_utility(self, x: Union[tf.Tensor, np.ndarray, pd.DataFrame]) -&gt; np.ndarray:\n    \"\"\"Get the utility of each alternative for a given set of observations.\n\n    Args:\n        x: The input data. It can be a tf.Tensor, np.ndarray or pd.DataFrame.\n\n    Returns:\n        Numpy array with the utility of each alternative for each observation in the input data.\n    \"\"\"\n    # This method is not supported for ensemble models\n    raise NotSupportedError(\"This method is not supported for ensemble models.\")\n</code></pre>"},{"location":"reference/runn/models/ensemble_dnn/#runn.models.ensemble_dnn.EnsembleDNN.load","title":"<code>load(path)</code>","text":"<p>Load the model from a file.</p> PARAMETER  DESCRIPTION <code>path</code> <p>Path to the file where the model is saved.</p> <p> TYPE: <code>str</code> </p> Source code in <code>runn/models/ensemble_dnn.py</code> <pre><code>def load(self, path: str) -&gt; None:\n    \"\"\"Load the model from a file.\n\n    Args:\n        path: Path to the file where the model is saved.\n    \"\"\"\n    if not isinstance(path, str):\n        raise ValueError(\"The 'path' parameter should be a string.\")\n    # Check that the str ends with .zip\n    if not path.endswith(\".zip\"):\n        raise ValueError(\"The 'path' parameter should be a .zip file.\")\n    else:\n        # Remove the .zip extension\n        aux_files = path[:-4]\n        # Get the last index of the '/' character\n        idx = aux_files.rfind(\"/\")\n        # Get the name of the file without the path\n        aux_name = aux_files[idx + 1 :]\n\n    try:\n        # Extract the files inside an temporal auxiliary folder\n        os.mkdir(aux_files)\n        with ZipFile(path, \"r\") as zip:\n            zip.extractall(path=aux_files)\n\n        # Load model info\n        with open(aux_files + \"/\" + aux_name + \"_info.json\", \"r\") as f:\n            model_info = json.load(f)\n        if model_info[\"model\"] != \"EnsembleDNN\":\n            msg = (\n                \"The model in the file is not a EnsembleDNN model. The model cannot be loaded.\",\n                \"Please try using the '{}' model instead.\".format(model_info[\"model\"]),\n            )\n            raise ValueError(msg)\n\n        # Check runn version\n        major, minor, patch = model_info[\"runn_version\"].split(\".\")\n        if (\n            int(major) &gt; int(runn.__version__.split(\".\")[0])\n            or (\n                int(major) == int(runn.__version__.split(\".\")[0])\n                and int(minor) &gt; int(runn.__version__.split(\".\")[1])\n            )\n            or (\n                int(major) == int(runn.__version__.split(\".\")[0])\n                and int(minor) == int(runn.__version__.split(\".\")[1])\n                and int(patch) &gt; int(runn.__version__.split(\".\")[2])\n            )\n        ):\n            msg = (\n                \"The model was created with a newer version of runn ({}). \"\n                \"Please update runn to version {} or higher.\".format(model_info[\"runn_version\"], runn.__version__)\n            )\n            raise IncompatibleVersionError(msg)\n\n        # Load the parameters of the model\n        (\n            self.attributes,\n            self.n_alt,\n            self.n_ensembles,\n            self.layers_dim,\n            self.activation,\n            self.regularizer,\n            self.regularization_rate,\n            self.dropout,\n            self.batch_norm,\n            self.learning_rate,\n            self.optimizer,\n            self.loss,\n            self.metrics,\n            self.n_jobs,\n        ) = pickle.load(open(aux_files + \"/\" + aux_name + \"_params.pkl\", \"rb\"))\n\n        # Load the individual DNN models\n        self.ensemble_pool = []\n        for i in range(self.n_ensembles):\n            self.ensemble_pool.append(\n                DNN(filename=aux_files + \"/\" + aux_name + \"_DNN_model_{}.zip\".format(i + 1), warnings=False)\n            )\n\n        # Load the ensemble keras model\n        self._build()\n        self.keras_model.load_weights(aux_files + \"/\" + aux_name + \"_model.h5\")\n\n        # Load the history\n        self.history = pickle.load(open(aux_files + \"/\" + aux_name + \"_history.pkl\", \"rb\"))\n        self.fitted = model_info[\"fitted\"]\n    except Exception as e:\n        raise e\n    finally:\n        # Delete the auxiliary folder\n        for file in os.listdir(aux_files):\n            os.remove(aux_files + \"/\" + file)\n        os.rmdir(aux_files)\n</code></pre>"},{"location":"reference/runn/models/ensemble_dnn/#runn.models.ensemble_dnn.EnsembleDNN.plot_model","title":"<code>plot_model(ensemble=True, **kwargs)</code>","text":"<p>Generate a graphical representation of the ensemble model.</p> PARAMETER  DESCRIPTION <code>ensemble</code> <p>Whether to plot the ensemble model or the individual DNN models. Default: True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>kwargs</code> <p>Additional arguments passed to the 'plot_model' function. See the documentation of the base class for more details.</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>runn/models/ensemble_dnn.py</code> <pre><code>def plot_model(self, ensemble: bool = True, **kwargs) -&gt; None:\n    \"\"\"Generate a graphical representation of the ensemble model.\n\n    Args:\n        ensemble: Whether to plot the ensemble model or the individual DNN models. Default: True.\n        kwargs: Additional arguments passed to the 'plot_model' function. See the documentation of the\n            base class for more details.\n    \"\"\"\n    if not ensemble:\n        # Plot an individual DNN model\n        if self.ensemble_pool is None or len(self.ensemble_pool) == 0 or self.ensemble_pool[0].keras_model is None:\n            msg = (\n                \"The individual DNN models have not been initialized yet. \"\n                \"Please initialize the ensemble model first.\"\n            )\n            raise ValueError(msg)\n        return self.ensemble_pool[0].plot_model(**kwargs)\n    elif ensemble:\n        # Plot the ensemble model\n        if self.keras_model is None:\n            msg = \"The ensemble model has not been constructed yet. Please call the 'fit' method first.\"\n            raise ValueError(msg)\n        return super().plot_model(**kwargs)\n</code></pre>"},{"location":"reference/runn/models/ensemble_dnn/#runn.models.ensemble_dnn.EnsembleDNN.save","title":"<code>save(path='model.zip')</code>","text":"<p>Save the model to a file.</p> PARAMETER  DESCRIPTION <code>path</code> <p>Path to the file where the model will be saved. Default: 'model.zip'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'model.zip'</code> </p> Source code in <code>runn/models/ensemble_dnn.py</code> <pre><code>def save(self, path: str = \"model.zip\") -&gt; None:\n    \"\"\"Save the model to a file.\n\n    Args:\n        path: Path to the file where the model will be saved. Default: 'model.zip'.\n    \"\"\"\n    if not isinstance(path, str):\n        raise ValueError(\"The 'path' parameter should be a string.\")\n    if path[-4:] != \".zip\":\n        path += \".zip\"\n    aux_files = path[:-4]\n\n    files = []\n    # Save model info as json\n    model_info = {\n        \"model\": \"EnsembleDNN\",\n        \"runn_version\": runn.__version__,\n        \"creation_date\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"fitted\": self.fitted,\n    }\n    with open(aux_files + \"_info.json\", \"w\") as f:\n        json.dump(model_info, f)\n    files.append(aux_files + \"_info.json\")\n\n    # Save the parameters of the model\n    # Save all the parameters of the model in a pickle file except the keras model\n    pickle.dump(\n        [\n            self.attributes,\n            self.n_alt,\n            self.n_ensembles,\n            self.layers_dim,\n            self.activation,\n            self.regularizer,\n            self.regularization_rate,\n            self.dropout,\n            self.batch_norm,\n            self.learning_rate,\n            self.optimizer,\n            self.loss,\n            self.metrics,\n            self.n_jobs,\n        ],\n        open(aux_files + \"_params.pkl\", \"wb\"),\n    )\n    files.append(aux_files + \"_params.pkl\")\n\n    # Save the keras ensemble model\n    self.keras_model.save_weights(aux_files + \"_model.h5\")\n    files.append(aux_files + \"_model.h5\")\n\n    # Save the individual DNN models\n    for i in range(self.n_ensembles):\n        self.ensemble_pool[i].save(aux_files + \"_DNN_model_{}.zip\".format(i + 1))\n        files.append(aux_files + \"_DNN_model_{}.zip\".format(i + 1))\n\n    # Save the history\n    pickle.dump(self.history, open(aux_files + \"_history.pkl\", \"wb\"))\n    files.append(aux_files + \"_history.pkl\")\n\n    # Compress all the files\n    with ZipFile(path, \"w\") as zip:\n        for file in files:\n            zip.write(file, os.path.basename(file))\n\n    # Delete the auxiliary files\n    for file in files:\n        os.remove(file)\n</code></pre>"},{"location":"reference/runn/models/ensemble_dnn/#runn.models.ensemble_dnn.EnsembleDNN.summary","title":"<code>summary(ensemble=True, line_length=100, **kwargs)</code>","text":"<p>Print a summary of the ensemble model.</p> PARAMETER  DESCRIPTION <code>ensemble</code> <p>If True, print the summary of the ensemble model. If False, print the summary of an individual DNN model. Default: True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>line_length</code> <p>Total length of printed lines. Default: 100.</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>**kwargs</code> <p>Additional arguments passed to the keras model. See tf.keras.Model.summary() for details.</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>runn/models/ensemble_dnn.py</code> <pre><code>def summary(self, ensemble: bool = True, line_length: int = 100, **kwargs) -&gt; None:\n    \"\"\"Print a summary of the ensemble model.\n\n    Args:\n        ensemble: If True, print the summary of the ensemble model. If False, print the summary of an individual\n            DNN model. Default: True.\n        line_length: Total length of printed lines. Default: 100.\n        **kwargs: Additional arguments passed to the keras model. See tf.keras.Model.summary() for details.\n    \"\"\"\n    if not ensemble:\n        # Print the summary of an individual DNN model\n        print(\"------ {} ------\".format(self.__class__.__name__))\n        print(\"Number of DNN models in the ensemble: %d\" % self.n_ensembles)\n        self._print_data_summary(line_length=line_length)\n        if self.ensemble_pool is None or len(self.ensemble_pool) == 0 or self.ensemble_pool[0].keras_model is None:\n            msg = (\n                \"The individual DNN models have not been initialized yet. \"\n                \"Please initialize the ensemble model first.\"\n            )\n            raise ValueError(msg)\n        print(\"\\nSummary of the individual DNN model used in the ensemble:\")\n        self.ensemble_pool[0].keras_model.summary()\n    elif ensemble:\n        # Print the summary of the ensemble model\n        if self.keras_model is None:\n            msg = \"The ensemble model has not been constructed yet. Please call the 'fit' method first.\"\n            raise ValueError(msg)\n        super().summary()\n</code></pre>"},{"location":"reference/runn/models/runn/","title":"runn.models.runn","text":""},{"location":"reference/runn/models/runn/#runn.models.runn.warning_manager","title":"<code>warning_manager = WarningManager()</code>  <code>module-attribute</code>","text":""},{"location":"reference/runn/models/runn/#runn.models.runn.RUNN","title":"<code>RUNN(attributes=None, n_alt=None, layers_dim=[25, 25], regularizer=None, regularization_rate=0.001, learning_rate=0.001, optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], filename=None, warnings=True)</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>runn/models/base.py</code> <pre><code>def __init__(\n    self,\n    attributes: Optional[list] = None,\n    n_alt: Optional[int] = None,\n    layers_dim: list = [25, 25],\n    regularizer: Optional[str] = None,\n    regularization_rate: float = 0.001,\n    learning_rate: float = 0.001,\n    optimizer: Union[str, tf.keras.optimizers.Optimizer] = \"adam\",\n    loss: Union[str, tf.keras.losses.Loss] = \"categorical_crossentropy\",\n    metrics: list = [\"accuracy\"],\n    filename: Optional[str] = None,\n    warnings: bool = True,\n) -&gt; None:\n    self._initialize_base_variables(warnings=warnings)\n    if filename is None:\n        # Initialize new model\n        self._initialize_base_params(\n            attributes=attributes,\n            n_alt=n_alt,\n            layers_dim=layers_dim,\n            regularizer=regularizer,\n            regularization_rate=regularization_rate,\n            learning_rate=learning_rate,\n            optimizer=optimizer,\n            loss=loss,\n            metrics=metrics,\n        )\n    elif isinstance(filename, str):\n        # Load model from file\n        self.load(filename)\n    else:\n        raise ValueError(\"The 'filename' parameter should be a string.\")\n</code></pre>"},{"location":"reference/runn/plot_model/","title":"runn.plot_model","text":"<p>Utilities related to model visualization.</p> <p>This file is based on the implementation https://github.com/dario-passos/plot_model/tree/master which is a for of https://github.com/Qinbf/plot_model.git distributed under MIT license.</p>"},{"location":"reference/runn/plot_model/#runn.plot_model.add_edge","title":"<code>add_edge(dot, src, dst, output_shape=None)</code>","text":"Source code in <code>runn/plot_model.py</code> <pre><code>def add_edge(dot, src, dst, output_shape=None):\n    if not dot.get_edge(src, dst):\n        if output_shape:\n            dot.add_edge(pydot.Edge(src, dst, label=output_shape))\n        else:\n            dot.add_edge(pydot.Edge(src, dst))\n</code></pre>"},{"location":"reference/runn/plot_model/#runn.plot_model.check_pydot","title":"<code>check_pydot()</code>","text":"<p>Returns True if PyDot and Graphviz are available.</p> Source code in <code>runn/plot_model.py</code> <pre><code>def check_pydot():\n    \"\"\"Returns True if PyDot and Graphviz are available.\"\"\"\n    if pydot is None:\n        return False\n    try:\n        # Attempt to create an image of a blank graph\n        # to check the pydot/graphviz installation.\n        pydot.Dot.create(pydot.Dot())\n        return True\n    except OSError:\n        return False\n</code></pre>"},{"location":"reference/runn/plot_model/#runn.plot_model.is_wrapped_model","title":"<code>is_wrapped_model(layer)</code>","text":"Source code in <code>runn/plot_model.py</code> <pre><code>def is_wrapped_model(layer):\n    from tensorflow.keras import Model as Network\n    from tensorflow.keras.layers import Wrapper\n\n    return isinstance(layer, Wrapper) and isinstance(layer.layer, Network)\n</code></pre>"},{"location":"reference/runn/plot_model/#runn.plot_model.model_to_dot","title":"<code>model_to_dot(model, show_shapes=False, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96, style=0, color=True, subgraph=False)</code>","text":"<p>Convert a Keras model to dot format.</p> PARAMETER  DESCRIPTION <code>model</code> <p>A Keras model instance.</p> <p> </p> <code>show_shapes</code> <p>whether to display shape information.</p> <p> DEFAULT: <code>False</code> </p> <code>show_layer_names</code> <p>whether to display layer names.</p> <p> DEFAULT: <code>True</code> </p> <code>rankdir</code> <p><code>rankdir</code> argument passed to PyDot,   a string specifying the format of the plot:   'TB' creates a vertical plot;   'LR' creates a horizontal plot.</p> <p> DEFAULT: <code>'TB'</code> </p> <code>expand_nested</code> <p>whether to expand nested models into clusters.</p> <p> DEFAULT: <code>False</code> </p> <code>dpi</code> <p>Dots per inch.</p> <p> DEFAULT: <code>96</code> </p> <code>style</code> <p>value 0,1.</p> <p> DEFAULT: <code>0</code> </p> <code>color</code> <p>whether to display color.</p> <p> DEFAULT: <code>True</code> </p> <code>subgraph</code> <p>whether to return a <code>pydot.Cluster</code> instance.</p> <p> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <p>A <code>pydot.Dot</code> instance representing the Keras model or</p> <p>a <code>pydot.Cluster</code> instance representing nested model if</p> <p><code>subgraph=True</code>.</p> RAISES DESCRIPTION <code>ImportError</code> <p>if graphviz or pydot are not available.</p> Source code in <code>runn/plot_model.py</code> <pre><code>def model_to_dot(\n    model,\n    show_shapes=False,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=96,\n    style=0,\n    color=True,\n    subgraph=False,\n):\n    \"\"\"Convert a Keras model to dot format.\n\n    Arguments:\n      model: A Keras model instance.\n      show_shapes: whether to display shape information.\n      show_layer_names: whether to display layer names.\n      rankdir: `rankdir` argument passed to PyDot,\n          a string specifying the format of the plot:\n          'TB' creates a vertical plot;\n          'LR' creates a horizontal plot.\n      expand_nested: whether to expand nested models into clusters.\n      dpi: Dots per inch.\n      style: value 0,1.\n      color: whether to display color.\n      subgraph: whether to return a `pydot.Cluster` instance.\n\n    Returns:\n      A `pydot.Dot` instance representing the Keras model or\n      a `pydot.Cluster` instance representing nested model if\n      `subgraph=True`.\n\n    Raises:\n      ImportError: if graphviz or pydot are not available.\n    \"\"\"\n    from tensorflow.keras import Model as Network\n    from tensorflow.keras.layers import Wrapper\n    from tensorflow.python.keras.engine import sequential\n\n    if not check_pydot():\n        if \"IPython.core.magics.namespace\" in sys.modules:\n            # We don't raise an exception here in order to avoid crashing notebook\n            # tests where graphviz is not available.\n            print(\"Failed to import pydot. You must install pydot\" \" and graphviz for `pydotprint` to work.\")\n            return\n        else:\n            raise ImportError(\n                \"Failed to import pydot. You must install pydot\" \" and graphviz for `pydotprint` to work.\"\n            )\n\n    if subgraph:\n        dot = pydot.Cluster(style=\"dashed\", graph_name=model.name)\n        dot.set(\"label\", model.name)\n        dot.set(\"labeljust\", \"l\")\n    else:\n        dot = pydot.Dot()\n        dot.set(\"rankdir\", rankdir)\n        dot.set(\"concentrate\", True)\n        dot.set(\"dpi\", dpi)\n        dot.set_node_defaults(shape=\"record\")\n\n    sub_n_first_node = {}\n    sub_n_last_node = {}\n    sub_w_first_node = {}\n    sub_w_last_node = {}\n\n    if not model._is_graph_network:\n        node = pydot.Node(str(id(model)), label=model.name)\n        dot.add_node(node)\n        return dot\n    elif isinstance(model, sequential.Sequential):\n        if not model.built:\n            model.build()\n    layers = model.layers\n    len(layers)\n\n    # Create graph nodes.\n    for i, layer in enumerate(layers):\n        layer_id = str(id(layer))\n\n        # Append a wrapped layer's label to node's label, if it exists.\n        layer_name = layer.name\n        class_name = layer.__class__.__name__\n        class_name_lower = class_name.lower()\n        config = 0\n        try:\n            config = layer.get_config()\n        except Exception:\n            pass\n\n        if isinstance(layer, Wrapper):\n            if expand_nested and isinstance(layer.layer, Network):\n                submodel_wrapper = model_to_dot(\n                    layer.layer, show_shapes, show_layer_names, rankdir, expand_nested, subgraph=True\n                )\n                # sub_w : submodel_wrapper\n                sub_w_nodes = submodel_wrapper.get_nodes()\n                sub_w_first_node[layer.layer.name] = sub_w_nodes[0]\n                sub_w_last_node[layer.layer.name] = sub_w_nodes[-1]\n                dot.add_subgraph(submodel_wrapper)\n            else:\n                layer_name = \"{}({})\".format(layer_name, layer.layer.name)\n                child_class_name = layer.layer.__class__.__name__\n                class_name = \"{}({})\".format(class_name, child_class_name)\n\n        if expand_nested and isinstance(layer, Network):\n            submodel_not_wrapper = model_to_dot(\n                layer, show_shapes, show_layer_names, rankdir, expand_nested, subgraph=True\n            )\n            # sub_n : submodel_not_wrapper\n            sub_n_nodes = submodel_not_wrapper.get_nodes()\n            sub_n_first_node[layer.name] = sub_n_nodes[0]\n            sub_n_last_node[layer.name] = sub_n_nodes[-1]\n            dot.add_subgraph(submodel_not_wrapper)\n\n        # Create node's label.\n\n        if show_layer_names:\n            label = \"{}: {}\".format(layer_name, class_name)\n            inputs = re.compile(\"input\")\n            if inputs.findall(class_name_lower):\n                pass\n            else:\n                if config != 0:\n                    conv = re.compile(\"conv\")\n                    if conv.findall(class_name_lower):\n                        label = \"{}:{},{}|kernel:{}  strides:{}\".format(\n                            layer_name, class_name, config[\"padding\"], config[\"kernel_size\"], config[\"strides\"]\n                        )\n                    pool = re.compile(\"pool\")\n                    if pool.findall(class_name_lower) and class_name_lower[:6] != \"global\":\n                        label = \"{}:{},{}|kernel:{}  strides:{}\".format(\n                            layer_name, class_name, config[\"padding\"], config[\"pool_size\"], config[\"strides\"]\n                        )\n                    activation = re.compile(\"activation\")\n                    if activation.findall(class_name_lower):\n                        label = \"{}:{}|{}\".format(layer_name, class_name, config[\"activation\"])\n                    dropout = re.compile(\"dropout\")\n                    if dropout.findall(class_name_lower):\n                        label = \"{}:{}|{}\".format(layer_name, class_name, config[\"rate\"])\n                    dense = re.compile(\"dense\")\n                    if dense.findall(class_name_lower):\n                        label = \"{}:{}|{}\".format(layer_name, class_name, config[\"activation\"])\n\n        else:\n            label = \"{}\".format(class_name)\n            inputs = re.compile(\"input\")\n            if inputs.findall(class_name_lower):\n                pass\n            else:\n                if config != 0:\n                    conv = re.compile(\"conv\")\n                    if conv.findall(class_name_lower):\n                        label = \"{},{}|kernel:{}  strides:{}\".format(\n                            class_name, config[\"padding\"], config[\"kernel_size\"], config[\"strides\"]\n                        )\n                    pool = re.compile(\"pool\")\n                    if pool.findall(class_name_lower) and class_name_lower[:6] != \"global\":\n                        label = \"{},{}|kernel:{}  strides:{}\".format(\n                            class_name, config[\"padding\"], config[\"pool_size\"], config[\"strides\"]\n                        )\n                    activation = re.compile(\"activation\")\n                    if activation.findall(class_name_lower):\n                        label = \"{}|{}\".format(class_name, config[\"activation\"])\n                    dropout = re.compile(\"dropout\")\n                    if dropout.findall(class_name_lower):\n                        label = \"{}|{}\".format(class_name, config[\"rate\"])\n                    dense = re.compile(\"dense\")\n                    if dense.findall(class_name_lower):\n                        label = \"{}|{}\".format(class_name, config[\"activation\"])\n\n        # Rebuild the label as a table including input/output shapes.\n        if show_shapes:\n\n            def format_shape(shape):\n                return str(shape).replace(str(None), \"None\")\n\n            try:\n                outputlabels = format_shape(layer.output_shape)\n            except AttributeError:\n                outputlabels = \"?\"\n            if hasattr(layer, \"input_shape\"):\n                inputlabels = format_shape(layer.input_shape)\n            elif hasattr(layer, \"input_shapes\"):\n                inputlabels = \", \".join([format_shape(ishape) for ishape in layer.input_shapes])\n            else:\n                inputlabels = \"?\"\n\n            if style == 0:\n                inputs = re.compile(\"input\")\n                if inputs.findall(class_name_lower):\n                    label = \"{%s}|{input:}|{%s}\" % (label, inputlabels)\n                else:\n                    for i, node in enumerate(layer._inbound_nodes):\n                        for outbound_layer in nest.flatten(node.outbound_layer):\n                            if outbound_layer.outbound_nodes == []:\n                                label = \"{%s}|{output:}|{%s}\" % (label, outputlabels)\n                            else:\n                                label = \"{%s}\" % (label)\n            elif style == 1:\n                label = \"{%s}|{input:|output:}|{{%s}|{%s}}\" % (label, inputlabels, outputlabels)\n\n        if not expand_nested or not isinstance(layer, Network):\n            if color is True:\n                inputs = re.compile(\"input\")\n                conv = re.compile(\"conv\")\n                pool = re.compile(\"pool\")\n                normalization = re.compile(\"normalization\")\n                activation = re.compile(\"activation\")\n                dropout = re.compile(\"dropout\")\n                dense = re.compile(\"dense\")\n                padding = re.compile(\"padding\")\n                concatenate = re.compile(\"concatenate\")\n                rnn = re.compile(\"rnn\")\n                lstm = re.compile(\"lstm\")\n                gru = re.compile(\"gru\")\n                bidirectional = re.compile(\"bidirectional\")\n                if inputs.findall(class_name_lower):\n                    node = pydot.Node(layer_id, label=label, fillcolor=\"deeppink\", style=\"filled\")\n                elif conv.findall(class_name_lower):\n                    node = pydot.Node(layer_id, label=label, fillcolor=\"cyan\", style=\"filled\")\n                elif pool.findall(class_name_lower):\n                    node = pydot.Node(layer_id, label=label, fillcolor=\"chartreuse\", style=\"filled\")\n                elif normalization.findall(class_name_lower):\n                    node = pydot.Node(layer_id, label=label, fillcolor=\"dodgerblue1\", style=\"filled\")\n                elif activation.findall(class_name_lower):\n                    node = pydot.Node(layer_id, label=label, fillcolor=\"pink\", style=\"filled\")\n                elif dropout.findall(class_name_lower):\n                    node = pydot.Node(layer_id, label=label, fillcolor=\"darkorange\", style=\"filled\")\n                elif dense.findall(class_name_lower):\n                    node = pydot.Node(layer_id, label=label, fillcolor=\"darkorchid1\", style=\"filled\")\n                elif padding.findall(class_name_lower):\n                    node = pydot.Node(layer_id, label=label, fillcolor=\"beige\", style=\"filled\")\n                elif concatenate.findall(class_name_lower):\n                    node = pydot.Node(layer_id, label=label, fillcolor=\"tomato\", style=\"filled\")\n                elif (\n                    rnn.findall(class_name_lower)\n                    or lstm.findall(class_name_lower)\n                    or gru.findall(class_name_lower)\n                    or bidirectional.findall(class_name_lower)\n                ):\n                    node = pydot.Node(layer_id, label=label, fillcolor=\"yellow1\", style=\"filled\")\n                else:\n                    node = pydot.Node(layer_id, label=label, fillcolor=\"gold\", style=\"filled\")\n            else:\n                node = pydot.Node(layer_id, label=label)\n            dot.add_node(node)\n\n    # Connect nodes with edges.\n    for j, layer in enumerate(layers):\n        # print(layer)\n        # print(layer.output_shape)\n        def format_shape(shape):\n            return \" \" + str(shape).replace(str(None), \"None\")\n\n        layer_id = str(id(layer))\n        for i, node in enumerate(layer._inbound_nodes):\n            node_key = layer.name + \"_ib-\" + str(i)\n            if node_key in model._network_nodes:\n                for inbound_layer in nest.flatten(node.inbound_layers):\n                    inbound_layer_id = str(id(inbound_layer))\n                    if not expand_nested:\n                        assert dot.get_node(inbound_layer_id)\n                        assert dot.get_node(layer_id)\n                        if style == 0:\n                            try:\n                                add_edge(dot, inbound_layer_id, layer_id, format_shape(inbound_layer.output_shape))\n                            except Exception:\n                                add_edge(dot, inbound_layer_id, layer_id, \"?\")\n                        elif style == 1:\n                            add_edge(dot, inbound_layer_id, layer_id)\n                    else:\n                        # if inbound_layer is not Model or wrapped Model\n                        if not isinstance(inbound_layer, Network) and not is_wrapped_model(inbound_layer):\n                            # if current layer is not Model or wrapped Model\n                            if not isinstance(layer, Network) and not is_wrapped_model(layer):\n                                assert dot.get_node(inbound_layer_id)\n                                assert dot.get_node(layer_id)\n                                if style == 0:\n                                    try:\n                                        add_edge(\n                                            dot, inbound_layer_id, layer_id, format_shape(inbound_layer.output_shape)\n                                        )\n                                    except Exception:\n                                        add_edge(dot, inbound_layer_id, layer_id, \"?\")\n                                elif style == 1:\n                                    add_edge(dot, inbound_layer_id, layer_id)\n                            # if current layer is Model\n                            elif isinstance(layer, Network):\n                                if style == 0:\n                                    add_edge(\n                                        dot,\n                                        inbound_layer_id,\n                                        sub_n_first_node[layer.name].get_name(),\n                                        format_shape(inbound_layer.output_shape),\n                                    )\n                                elif style == 1:\n                                    add_edge(dot, inbound_layer_id, sub_n_first_node[layer.name].get_name())\n                            # if current layer is wrapped Model\n                            elif is_wrapped_model(layer):\n                                if style == 0:\n                                    try:\n                                        add_edge(\n                                            dot, inbound_layer_id, layer_id, format_shape(inbound_layer.output_shape)\n                                        )\n                                    except Exception:\n                                        add_edge(dot, inbound_layer_id, layer_id, \"?\")\n                                    name = sub_w_first_node[layer.layer.name].get_name()\n                                    add_edge(dot, layer_id, name, format_shape(layer.output_shape))\n                                elif style == 1:\n                                    add_edge(dot, inbound_layer_id, layer_id)\n                                    name = sub_w_first_node[layer.layer.name].get_name()\n                                    add_edge(dot, layer_id, name)\n                        # if inbound_layer is Model\n                        elif isinstance(inbound_layer, Network):\n                            name = sub_n_last_node[inbound_layer.name].get_name()\n                            if isinstance(layer, Network):\n                                output_name = sub_n_first_node[layer.name].get_name()\n                                if style == 0:\n                                    try:\n                                        add_edge(dot, name, output_name, format_shape(layer.output_shape))\n                                    except Exception:\n                                        add_edge(dot, name, output_name, \"?\")\n                                elif style == 1:\n                                    add_edge(dot, name, output_name)\n                            else:\n                                if style == 0:\n                                    try:\n                                        add_edge(dot, name, layer_id, format_shape(layer.output_shape))\n                                    except Exception:\n                                        add_edge(dot, name, layer_id, \"?\")\n                                elif style == 1:\n                                    add_edge(dot, name, layer_id)\n                        # if inbound_layer is wrapped Model\n                        elif is_wrapped_model(inbound_layer):\n                            inbound_layer_name = inbound_layer.layer.name\n                            if style == 0:\n                                try:\n                                    add_edge(\n                                        dot,\n                                        sub_w_last_node[inbound_layer_name].get_name(),\n                                        layer_id,\n                                        format_shape(inbound_layer.output_shape),\n                                    )\n                                except Exception:\n                                    add_edge(dot, sub_w_last_node[inbound_layer_name].get_name(), layer_id, \"?\")\n                            elif style == 1:\n                                add_edge(dot, sub_w_last_node[inbound_layer_name].get_name(), layer_id)\n\n    return dot\n</code></pre>"},{"location":"reference/runn/plot_model/#runn.plot_model.plot_model","title":"<code>plot_model(model, to_file='./model.png', show_shapes=True, show_layer_names=False, rankdir='TB', expand_nested=False, style=0, color=True, dpi=96)</code>","text":"<p>Converts a Keras model to dot format and save to a file.</p> PARAMETER  DESCRIPTION <code>model</code> <p>A Keras model instance</p> <p> </p> <code>to_file</code> <p>File name of the plot image.</p> <p> DEFAULT: <code>'./model.png'</code> </p> <code>show_shapes</code> <p>whether to display shape information.</p> <p> DEFAULT: <code>True</code> </p> <code>show_layer_names</code> <p>whether to display layer names.</p> <p> DEFAULT: <code>False</code> </p> <code>rankdir</code> <p><code>rankdir</code> argument passed to PyDot,   a string specifying the format of the plot:   'TB' creates a vertical plot;   'LR' creates a horizontal plot.</p> <p> DEFAULT: <code>'TB'</code> </p> <code>expand_nested</code> <p>Whether to expand nested models into clusters.</p> <p> DEFAULT: <code>False</code> </p> <code>style</code> <p>value 0,1.</p> <p> DEFAULT: <code>0</code> </p> <code>color</code> <p>whether to display color.</p> <p> DEFAULT: <code>True</code> </p> <code>dpi</code> <p>Dots per inch.</p> <p> DEFAULT: <code>96</code> </p> RETURNS DESCRIPTION <p>A Jupyter notebook Image object if Jupyter is installed.</p> <p>This enables in-line display of the model plots in notebooks.</p> Source code in <code>runn/plot_model.py</code> <pre><code>def plot_model(\n    model,\n    to_file=\"./model.png\",\n    show_shapes=True,\n    show_layer_names=False,\n    rankdir=\"TB\",\n    expand_nested=False,\n    style=0,\n    color=True,\n    dpi=96,\n):\n    \"\"\"Converts a Keras model to dot format and save to a file.\n\n    Arguments:\n      model: A Keras model instance\n      to_file: File name of the plot image.\n      show_shapes: whether to display shape information.\n      show_layer_names: whether to display layer names.\n      rankdir: `rankdir` argument passed to PyDot,\n          a string specifying the format of the plot:\n          'TB' creates a vertical plot;\n          'LR' creates a horizontal plot.\n      expand_nested: Whether to expand nested models into clusters.\n      style: value 0,1.\n      color: whether to display color.\n      dpi: Dots per inch.\n\n    Returns:\n      A Jupyter notebook Image object if Jupyter is installed.\n      This enables in-line display of the model plots in notebooks.\n    \"\"\"\n    assert style == 0 or style == 1\n    dot = model_to_dot(\n        model,\n        show_shapes=show_shapes,\n        show_layer_names=show_layer_names,\n        rankdir=rankdir,\n        expand_nested=expand_nested,\n        style=style,\n        color=color,\n        dpi=dpi,\n    )\n    if dot is None:\n        return\n    _, extension = os.path.splitext(to_file)\n    if not extension:\n        extension = \"png\"\n    else:\n        extension = extension[1:]\n    # Save image to disk.\n    dot.write(to_file, format=extension)\n    # Return the image as a Jupyter Image object, to be displayed in-line.\n    # Note that we cannot easily detect whether the code is running in a\n    # notebook, and thus we always return the Image if Jupyter is available.\n    try:\n        from IPython import display\n\n        return display.Image(filename=to_file)\n    except ImportError:\n        pass\n</code></pre>"},{"location":"reference/runn/utils/","title":"runn.utils","text":""},{"location":"reference/runn/utils/#runn.utils.IncompatibleVersionError","title":"<code>IncompatibleVersionError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Raised when the version of runn used to create the model is not compatible with the current version.</p>"},{"location":"reference/runn/utils/#runn.utils.NotSupportedError","title":"<code>NotSupportedError</code>","text":"<p>             Bases: <code>Exception</code></p> <p>Raised when a not supported operation for a given model is called.</p>"},{"location":"reference/runn/utils/#runn.utils.ProgressBar","title":"<code>ProgressBar(total, bar_length=25, filled_mark='=', suffix='')</code>","text":"<p>A simple progress bar.</p> PARAMETER  DESCRIPTION <code>total</code> <p>The total number of steps.</p> <p> </p> <code>bar_length</code> <p>The length of the bar.</p> <p> DEFAULT: <code>25</code> </p> <code>filled_mark</code> <p>The character to fill the bar.</p> <p> DEFAULT: <code>'='</code> </p> <code>suffix</code> <p>The suffix to be shown at the end of the bar.</p> <p> DEFAULT: <code>''</code> </p> Source code in <code>runn/utils.py</code> <pre><code>def __init__(self, total, bar_length=25, filled_mark=\"=\", suffix=\"\"):\n    self.total = total\n    self.bar_length = bar_length\n    self.filled_mark = filled_mark\n    self.suffix = suffix\n    self.start_time = None\n</code></pre>"},{"location":"reference/runn/utils/#runn.utils.ProgressBar.bar_length","title":"<code>bar_length = bar_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/runn/utils/#runn.utils.ProgressBar.filled_mark","title":"<code>filled_mark = filled_mark</code>  <code>instance-attribute</code>","text":""},{"location":"reference/runn/utils/#runn.utils.ProgressBar.start_time","title":"<code>start_time = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/runn/utils/#runn.utils.ProgressBar.suffix","title":"<code>suffix = suffix</code>  <code>instance-attribute</code>","text":""},{"location":"reference/runn/utils/#runn.utils.ProgressBar.total","title":"<code>total = total</code>  <code>instance-attribute</code>","text":""},{"location":"reference/runn/utils/#runn.utils.ProgressBar.update","title":"<code>update(count_value, value_dict={})</code>","text":"<p>Update the progress bar.</p> PARAMETER  DESCRIPTION <code>count_value</code> <p>The current value.</p> <p> </p> <code>value_dict</code> <p>A dictionary of values to be shown at the end of the bar.</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>runn/utils.py</code> <pre><code>def update(self, count_value, value_dict={}):\n    \"\"\"Update the progress bar.\n\n    Args:\n        count_value: The current value.\n        value_dict: A dictionary of values to be shown at the end of the bar.\n    \"\"\"\n    if self.start_time is None:\n        self.start_time = time.time()\n    if count_value &gt; self.total:\n        count_value = self.total\n    filled_up_Length = int(round(self.bar_length * count_value / float(self.total)))\n    percentage = int(round(100.0 * count_value / float(self.total)))\n    bar = self.filled_mark * filled_up_Length + \" \" * (self.bar_length - filled_up_Length)\n    time_sufix = \" - Elapsed: {:d}s\".format(int(round(time.time() - self.start_time)))\n    value_sufix = \"\"\n    if len(value_dict) &gt; 0:\n        for key, value in value_dict.items():\n            value_sufix += \" - {}: {}\".format(key, value)\n    n_digits = len(str(self.total))\n    sys.stdout.write(\n        \"\\r {:{}}/{} ({:3d}%) [{}] {}{}\".format(\n            count_value, n_digits, self.total, percentage, bar, time_sufix, value_sufix\n        )\n    )\n    sys.stdout.flush()\n    if count_value &gt;= self.total:\n        sys.stdout.write(\"\\n\")\n        sys.stdout.flush()\n        self.start_time = None\n</code></pre>"},{"location":"reference/runn/utils/#runn.utils.WarningManager","title":"<code>WarningManager</code>","text":"<p>Singleton class to manage warnings.</p>"},{"location":"reference/runn/utils/#runn.utils.WarningManager.set_show_warnings","title":"<code>set_show_warnings(show_warnings)</code>","text":"<p>Set whether to show warnings or not.</p> PARAMETER  DESCRIPTION <code>show_warnings</code> <p>Whether to show warnings or not.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>runn/utils.py</code> <pre><code>def set_show_warnings(self, show_warnings: bool) -&gt; None:\n    \"\"\"Set whether to show warnings or not.\n\n    Args:\n        show_warnings: Whether to show warnings or not.\n    \"\"\"\n    self.show_warnings = show_warnings\n</code></pre>"},{"location":"reference/runn/utils/#runn.utils.WarningManager.warn","title":"<code>warn(message)</code>","text":"<p>Show a warning message.</p> PARAMETER  DESCRIPTION <code>message</code> <p>The warning message.</p> <p> TYPE: <code>str</code> </p> Source code in <code>runn/utils.py</code> <pre><code>def warn(self, message: str) -&gt; None:\n    \"\"\"Show a warning message.\n\n    Args:\n        message: The warning message.\n    \"\"\"\n    if not isinstance(message, str):\n        raise ValueError(\"The message should be a string.\")\n    if self.show_warnings:\n        warnings.warn(message)\n</code></pre>"}]}